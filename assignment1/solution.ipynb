{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ELEC6910X Advanced Topics in AI and Healthcare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Holy Lovenia - 20814158***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from PIL import Image\n",
    "from pytorch3dunet.unet3d import losses\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import init\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import (\n",
    "    CenterCrop,\n",
    "    Compose,\n",
    "    Normalize,\n",
    "    RandomHorizontalFlip,\n",
    "    RandomResizedCrop,\n",
    "    Resize,\n",
    "    ToTensor,\n",
    ")\n",
    "from transformers import AutoFeatureExtractor, AutoModelForImageClassification, TrainingArguments, Trainer\n",
    "from tqdm import tqdm\n",
    "\n",
    "import datasets\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import surface_distance.metrics as sf\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchio as tio\n",
    "import torchmetrics\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "\n",
    "def set_all_seeds(seed):\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  torch.manual_seed(seed)\n",
    "  torch.cuda.manual_seed(seed)\n",
    "  torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_all_seeds(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem, you are required to implement a 3D segmentation network (e.g., 3d unet), including\n",
    "the model, dataloader, training/testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Problem1Dataset(Dataset):\n",
    "    def __init__(self, dir_path, column_names=[\"image\", \"label\"], resize_type=\"center\", resize_target_shape=(112, 112, 88), transform=None, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.dir_path = dir_path\n",
    "        self.column_names = column_names\n",
    "        self.transform = transform\n",
    "        self.resize_type = resize_type\n",
    "        self.resize_target_shape = resize_target_shape\n",
    "        self._init_transform_methods()\n",
    "        self._load_all_data_from_dir(dir_path)\n",
    "    \n",
    "    def _load_h5_data(self, file_path):\n",
    "        hf = h5py.File(file_path, \"r\")\n",
    "        return hf\n",
    "\n",
    "    def _load_all_data_from_dir(self, dir_path):\n",
    "        df_dict = {}\n",
    "        for col in self.column_names:\n",
    "            df_dict[col] = []\n",
    "\n",
    "        for file_name in os.listdir(dir_path):\n",
    "            file_path = os.path.join(dir_path, file_name)\n",
    "            if os.path.isfile(file_path) and file_path.endswith(\".h5\"):\n",
    "                data = self._load_h5_data(file_path)\n",
    "                for col in self.column_names:\n",
    "                    df_dict[col] += [np.array(data[col][:])]\n",
    "        self.dataset = pd.DataFrame.from_dict(df_dict)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        current_data = self.dataset.iloc[index]\n",
    "        transformed = self.set_transform(current_data[\"image\"], current_data[\"label\"])\n",
    "        return transformed\n",
    "\n",
    "    def _init_transform_methods(self):\n",
    "        self._random_affine = tio.RandomAffine(scales=(0.9, 1.2), degrees=15)\n",
    "        self._random_motion = tio.RandomMotion()\n",
    "        self._random_elastic_deformation = tio.RandomElasticDeformation()\n",
    "        self._random_blur = tio.RandomBlur()\n",
    "        self._random_transform = tio.OneOf({\n",
    "            self._random_affine: 0.25,\n",
    "            self._random_motion: 0.25,\n",
    "            self._random_elastic_deformation: 0.25,\n",
    "            self._random_blur: 0.25,\n",
    "        })\n",
    "        self._random_double = tio.Compose([self._random_transform, self._random_transform])\n",
    "        self._crop_or_pad = tio.CropOrPad(self.resize_target_shape)\n",
    "\n",
    "    def set_transform(self, data, label):\n",
    "        transformed_data, transformed_label = self.resize(data, label)\n",
    "\n",
    "        if self.transform is None:\n",
    "            return transformed_data, transformed_label\n",
    "        else:\n",
    "            if self.transform == \"random\":\n",
    "                transform_method = self._random_transform\n",
    "            elif self.transform == \"motion\":\n",
    "                transform_method = self._random_motion\n",
    "            elif self.transform == \"affine\":\n",
    "                transform_method = self._random_affine\n",
    "            elif self.transform == \"elastic_deformation\":\n",
    "                transform_method = self._random_elastic_deformation\n",
    "            elif self.transform == \"random_double\":\n",
    "                transform_method = self._random_double\n",
    "\n",
    "            transformed_data = np.expand_dims(transformed_data, axis=0)\n",
    "            transformed_data = transform_method(transformed_data)\n",
    "            transformed_data = np.squeeze(transformed_data, axis=0)\n",
    "\n",
    "            transformed_label = np.expand_dims(transformed_label, axis=0)\n",
    "            transformed_label = transform_method(transformed_label)\n",
    "            transformed_label = np.squeeze(transformed_label, axis=0)\n",
    "\n",
    "            return transformed_data, transformed_label\n",
    "\n",
    "    def resize(self, data, label):\n",
    "        if self.resize_type == \"center\":\n",
    "            transformed_data = np.expand_dims(data, axis=0)\n",
    "            transformed_data = self._crop_or_pad(transformed_data)\n",
    "            transformed_data = np.squeeze(transformed_data, axis=0)\n",
    "            transformed_label = np.expand_dims(label, axis=0)\n",
    "            transformed_label = self._crop_or_pad(transformed_label)\n",
    "            transformed_label = np.squeeze(transformed_label, axis=0)\n",
    "            return transformed_data, transformed_label\n",
    "        elif self.resize_type == \"random\":\n",
    "            return get_random_crop(data, label, crop_width=self.resize_target_shape[0], crop_height=self.resize_target_shape[1])\n",
    "\n",
    "def get_random_crop(data, label, crop_width, crop_height):\n",
    "    max_w = data.shape[1] - crop_width\n",
    "    max_h = data.shape[0] - crop_height\n",
    "    w = np.random.randint(0, max_w)\n",
    "    h = np.random.randint(0, max_h)\n",
    "    cropped_data = data[h: h + crop_height, w: w + crop_width, :]\n",
    "    cropped_label = label[h: h + crop_height, w: w + crop_width, :]\n",
    "    return cropped_data, cropped_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Problem1Dataset(\"./data/problem1_datas/train\", resize_type=\"random\", resize_target_shape=(112, 112, 88), transform=None)\n",
    "valid_dataset = Problem1Dataset(\"./data/problem1_datas/train\", resize_type=\"center\", resize_target_shape=(112, 112, 88), transform=None)\n",
    "test_dataset = Problem1Dataset(\"./data/problem1_datas/test\", resize_type=\"center\", resize_target_shape=(112, 112, 88), transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=14, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=14, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=14, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "\n",
    "def conv_layer(dim: int):\n",
    "    if dim == 3:\n",
    "        return nn.Conv3d\n",
    "    elif dim == 2:\n",
    "        return nn.Conv2d\n",
    "\n",
    "\n",
    "def get_conv_layer(in_channels: int,\n",
    "                   out_channels: int,\n",
    "                   kernel_size: int = 3,\n",
    "                   stride: int = 1,\n",
    "                   padding: int = 1,\n",
    "                   bias: bool = True,\n",
    "                   dim: int = 2):\n",
    "    return conv_layer(dim)(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding,\n",
    "                           bias=bias)\n",
    "\n",
    "\n",
    "def conv_transpose_layer(dim: int):\n",
    "    if dim == 3:\n",
    "        return nn.ConvTranspose3d\n",
    "    elif dim == 2:\n",
    "        return nn.ConvTranspose2d\n",
    "\n",
    "\n",
    "def get_up_layer(in_channels: int,\n",
    "                 out_channels: int,\n",
    "                 kernel_size: int = 2,\n",
    "                 stride: int = 2,\n",
    "                 dim: int = 3,\n",
    "                 up_mode: str = 'transposed',\n",
    "                 ):\n",
    "    if up_mode == 'transposed':\n",
    "        return conv_transpose_layer(dim)(in_channels, out_channels, kernel_size=kernel_size, stride=stride)\n",
    "    else:\n",
    "        return nn.Upsample(scale_factor=2.0, mode=up_mode)\n",
    "\n",
    "\n",
    "def maxpool_layer(dim: int):\n",
    "    if dim == 3:\n",
    "        return nn.MaxPool3d\n",
    "    elif dim == 2:\n",
    "        return nn.MaxPool2d\n",
    "\n",
    "\n",
    "def get_maxpool_layer(kernel_size: int = 2,\n",
    "                      stride: int = 2,\n",
    "                      padding: int = 0,\n",
    "                      dim: int = 2):\n",
    "    return maxpool_layer(dim=dim)(kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "\n",
    "\n",
    "def get_activation(activation: str):\n",
    "    if activation == 'relu':\n",
    "        return nn.ReLU()\n",
    "    elif activation == 'leaky':\n",
    "        return nn.LeakyReLU(negative_slope=0.1)\n",
    "    elif activation == 'elu':\n",
    "        return nn.ELU()\n",
    "\n",
    "\n",
    "def get_normalization(normalization: str,\n",
    "                      num_channels: int,\n",
    "                      dim: int):\n",
    "    if normalization == 'batch':\n",
    "        if dim == 3:\n",
    "            return nn.BatchNorm3d(num_channels)\n",
    "        elif dim == 2:\n",
    "            return nn.BatchNorm2d(num_channels)\n",
    "    elif normalization == 'instance':\n",
    "        if dim == 3:\n",
    "            return nn.InstanceNorm3d(num_channels)\n",
    "        elif dim == 2:\n",
    "            return nn.InstanceNorm2d(num_channels)\n",
    "    elif 'group' in normalization:\n",
    "        num_groups = int(normalization.partition('group')[-1])  # get the group size from string\n",
    "        return nn.GroupNorm(num_groups=num_groups, num_channels=num_channels)\n",
    "\n",
    "\n",
    "class Concatenate(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Concatenate, self).__init__()\n",
    "\n",
    "    def forward(self, layer_1, layer_2):\n",
    "        x = torch.cat((layer_1, layer_2), 1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DownBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    A helper Module that performs 2 Convolutions and 1 MaxPool.\n",
    "    An activation follows each convolution.\n",
    "    A normalization layer follows each convolution.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 out_channels: int,\n",
    "                 pooling: bool = True,\n",
    "                 activation: str = 'relu',\n",
    "                 normalization: str = None,\n",
    "                 dim: str = 2,\n",
    "                 conv_mode: str = 'same'):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.pooling = pooling\n",
    "        self.normalization = normalization\n",
    "        if conv_mode == 'same':\n",
    "            self.padding = 1\n",
    "        elif conv_mode == 'valid':\n",
    "            self.padding = 0\n",
    "        self.dim = dim\n",
    "        self.activation = activation\n",
    "\n",
    "        # conv layers\n",
    "        self.conv1 = get_conv_layer(self.in_channels, self.out_channels, kernel_size=3, stride=1, padding=self.padding,\n",
    "                                    bias=True, dim=self.dim)\n",
    "        self.conv2 = get_conv_layer(self.out_channels, self.out_channels, kernel_size=3, stride=1, padding=self.padding,\n",
    "                                    bias=True, dim=self.dim)\n",
    "\n",
    "        # pooling layer\n",
    "        if self.pooling:\n",
    "            self.pool = get_maxpool_layer(kernel_size=2, stride=2, padding=0, dim=self.dim)\n",
    "\n",
    "        # activation layers\n",
    "        self.act1 = get_activation(self.activation)\n",
    "        self.act2 = get_activation(self.activation)\n",
    "\n",
    "        # normalization layers\n",
    "        if self.normalization:\n",
    "            self.norm1 = get_normalization(normalization=self.normalization, num_channels=self.out_channels,\n",
    "                                           dim=self.dim)\n",
    "            self.norm2 = get_normalization(normalization=self.normalization, num_channels=self.out_channels,\n",
    "                                           dim=self.dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.conv1(x)  # convolution 1\n",
    "        y = self.act1(y)  # activation 1\n",
    "        if self.normalization:\n",
    "            y = self.norm1(y)  # normalization 1\n",
    "        y = self.conv2(y)  # convolution 2\n",
    "        y = self.act2(y)  # activation 2\n",
    "        if self.normalization:\n",
    "            y = self.norm2(y)  # normalization 2\n",
    "\n",
    "        before_pooling = y  # save the outputs before the pooling operation\n",
    "        if self.pooling:\n",
    "            y = self.pool(y)  # pooling\n",
    "        return y, before_pooling\n",
    "\n",
    "\n",
    "class UpBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    A helper Module that performs 2 Convolutions and 1 UpConvolution/Upsample.\n",
    "    An activation follows each convolution.\n",
    "    A normalization layer follows each convolution.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 out_channels: int,\n",
    "                 activation: str = 'relu',\n",
    "                 normalization: str = None,\n",
    "                 dim: int = 3,\n",
    "                 conv_mode: str = 'same',\n",
    "                 up_mode: str = 'transposed'\n",
    "                 ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.normalization = normalization\n",
    "        if conv_mode == 'same':\n",
    "            self.padding = 1\n",
    "        elif conv_mode == 'valid':\n",
    "            self.padding = 0\n",
    "        self.dim = dim\n",
    "        self.activation = activation\n",
    "        self.up_mode = up_mode\n",
    "\n",
    "        # upconvolution/upsample layer\n",
    "        self.up = get_up_layer(self.in_channels, self.out_channels, kernel_size=2, stride=2, dim=self.dim,\n",
    "                               up_mode=self.up_mode)\n",
    "\n",
    "        # conv layers\n",
    "        self.conv0 = get_conv_layer(self.in_channels, self.out_channels, kernel_size=1, stride=1, padding=0,\n",
    "                                    bias=True, dim=self.dim)\n",
    "        self.conv1 = get_conv_layer(2 * self.out_channels, self.out_channels, kernel_size=3, stride=1,\n",
    "                                    padding=self.padding,\n",
    "                                    bias=True, dim=self.dim)\n",
    "        self.conv2 = get_conv_layer(self.out_channels, self.out_channels, kernel_size=3, stride=1, padding=self.padding,\n",
    "                                    bias=True, dim=self.dim)\n",
    "\n",
    "        # activation layers\n",
    "        self.act0 = get_activation(self.activation)\n",
    "        self.act1 = get_activation(self.activation)\n",
    "        self.act2 = get_activation(self.activation)\n",
    "\n",
    "        # normalization layers\n",
    "        if self.normalization:\n",
    "            self.norm0 = get_normalization(normalization=self.normalization, num_channels=self.out_channels,\n",
    "                                           dim=self.dim)\n",
    "            self.norm1 = get_normalization(normalization=self.normalization, num_channels=self.out_channels,\n",
    "                                           dim=self.dim)\n",
    "            self.norm2 = get_normalization(normalization=self.normalization, num_channels=self.out_channels,\n",
    "                                           dim=self.dim)\n",
    "\n",
    "        # concatenate layer\n",
    "        self.concat = Concatenate()\n",
    "\n",
    "    def forward(self, encoder_layer, decoder_layer):\n",
    "        \"\"\" Forward pass\n",
    "        Arguments:\n",
    "            encoder_layer: Tensor from the encoder pathway\n",
    "            decoder_layer: Tensor from the decoder pathway (to be up'd)\n",
    "        \"\"\"\n",
    "        up_layer = self.up(decoder_layer)  # up-convolution/up-sampling\n",
    "\n",
    "        if self.up_mode != 'transposed':\n",
    "            # We need to reduce the channel dimension with a conv layer\n",
    "            up_layer = self.conv0(up_layer)  # convolution 0\n",
    "        up_layer = self.act0(up_layer)  # activation 0\n",
    "        if self.normalization:\n",
    "            up_layer = self.norm0(up_layer)  # normalization 0\n",
    "\n",
    "        merged_layer = self.concat(up_layer, encoder_layer)  # concatenation\n",
    "        y = self.conv1(merged_layer)  # convolution 1\n",
    "        y = self.act1(y)  # activation 1\n",
    "        if self.normalization:\n",
    "            y = self.norm1(y)  # normalization 1\n",
    "        y = self.conv2(y)  # convolution 2\n",
    "        y = self.act2(y)  # acivation 2\n",
    "        if self.normalization:\n",
    "            y = self.norm2(y)  # normalization 2\n",
    "        return y\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels: int = 1,\n",
    "                 out_channels: int = 2,\n",
    "                 n_blocks: int = 4,\n",
    "                 start_filters: int = 32,\n",
    "                 activation: str = 'relu',\n",
    "                 normalization: str = 'batch',\n",
    "                 conv_mode: str = 'same',\n",
    "                 dim: int = 2,\n",
    "                 up_mode: str = 'transposed'\n",
    "                 ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.n_blocks = n_blocks\n",
    "        self.start_filters = start_filters\n",
    "        self.activation = activation\n",
    "        self.normalization = normalization\n",
    "        self.conv_mode = conv_mode\n",
    "        self.dim = dim\n",
    "        self.up_mode = up_mode\n",
    "\n",
    "        self.down_blocks = []\n",
    "        self.up_blocks = []\n",
    "\n",
    "        # create encoder path\n",
    "        for i in range(self.n_blocks):\n",
    "            num_filters_in = self.in_channels if i == 0 else num_filters_out\n",
    "            num_filters_out = self.start_filters * (2 ** i)\n",
    "            pooling = True if i < self.n_blocks - 1 else False\n",
    "\n",
    "            down_block = DownBlock(in_channels=num_filters_in,\n",
    "                                   out_channels=num_filters_out,\n",
    "                                   pooling=pooling,\n",
    "                                   activation=self.activation,\n",
    "                                   normalization=self.normalization,\n",
    "                                   conv_mode=self.conv_mode,\n",
    "                                   dim=self.dim)\n",
    "\n",
    "            self.down_blocks.append(down_block)\n",
    "\n",
    "        # create decoder path (requires only n_blocks-1 blocks)\n",
    "        for i in range(n_blocks - 1):\n",
    "            num_filters_in = num_filters_out\n",
    "            num_filters_out = num_filters_in // 2\n",
    "\n",
    "            up_block = UpBlock(in_channels=num_filters_in,\n",
    "                               out_channels=num_filters_out,\n",
    "                               activation=self.activation,\n",
    "                               normalization=self.normalization,\n",
    "                               conv_mode=self.conv_mode,\n",
    "                               dim=self.dim,\n",
    "                               up_mode=self.up_mode)\n",
    "\n",
    "            self.up_blocks.append(up_block)\n",
    "\n",
    "        # final convolution\n",
    "        self.conv_final = get_conv_layer(num_filters_out, self.out_channels, kernel_size=1, stride=1, padding=0,\n",
    "                                         bias=True, dim=self.dim)\n",
    "\n",
    "        # add the list of modules to current module\n",
    "        self.down_blocks = nn.ModuleList(self.down_blocks)\n",
    "        self.up_blocks = nn.ModuleList(self.up_blocks)\n",
    "\n",
    "        # initialize the weights\n",
    "        self.initialize_parameters()\n",
    "\n",
    "    @staticmethod\n",
    "    def weight_init(module, method, **kwargs):\n",
    "        if isinstance(module, (nn.Conv3d, nn.Conv2d, nn.ConvTranspose3d, nn.ConvTranspose2d)):\n",
    "            method(module.weight, **kwargs)  # weights\n",
    "\n",
    "    @staticmethod\n",
    "    def bias_init(module, method, **kwargs):\n",
    "        if isinstance(module, (nn.Conv3d, nn.Conv2d, nn.ConvTranspose3d, nn.ConvTranspose2d)):\n",
    "            method(module.bias, **kwargs)  # bias\n",
    "\n",
    "    def initialize_parameters(self,\n",
    "                              method_weights=nn.init.xavier_uniform_,\n",
    "                              method_bias=nn.init.zeros_,\n",
    "                              kwargs_weights={},\n",
    "                              kwargs_bias={}\n",
    "                              ):\n",
    "        for module in self.modules():\n",
    "            self.weight_init(module, method_weights, **kwargs_weights)  # initialize weights\n",
    "            self.bias_init(module, method_bias, **kwargs_bias)  # initialize bias\n",
    "\n",
    "    def forward(self, x: torch.tensor):\n",
    "        encoder_output = []\n",
    "\n",
    "        # Encoder pathway\n",
    "        for module in self.down_blocks:\n",
    "            x, before_pooling = module(x)\n",
    "            encoder_output.append(before_pooling)\n",
    "\n",
    "        # Decoder pathway\n",
    "        for i, module in enumerate(self.up_blocks):\n",
    "            before_pool = encoder_output[-(i + 2)]\n",
    "            x = module(before_pool, x)\n",
    "\n",
    "        x = self.conv_final(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def __repr__(self):\n",
    "        attributes = {attr_key: self.__dict__[attr_key] for attr_key in self.__dict__.keys() if '_' not in attr_key[0] and 'training' not in attr_key}\n",
    "        d = {self.__class__.__name__: attributes}\n",
    "        return f'{d}'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and evaluation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred, label, threshold=0.8):\n",
    "    results = {}\n",
    "    results[\"dice\"] = torchmetrics.functional.dice(pred, label).item()\n",
    "    results[\"jaccard\"] = torchmetrics.functional.jaccard_index(pred, label, num_classes=2).item()\n",
    "    pred_bool = pred.cpu().detach().numpy() > threshold\n",
    "    pred_bool = np.reshape(pred_bool, (pred_bool.shape[0], -1))\n",
    "    label_bool = label.cpu().detach().numpy() > threshold\n",
    "    label_bool = np.reshape(label_bool, (label_bool.shape[0], -1))\n",
    "    surface_distances = sf.compute_surface_distances(label_bool, pred_bool, spacing_mm=(2, 2,))\n",
    "    results[\"avg_surface_dist\"] = sf.compute_average_surface_distance(surface_distances)[-1]\n",
    "    results[\"hausdorff\"] = sf.compute_robust_hausdorff(surface_distances, 0.95)\n",
    "    return results\n",
    "\n",
    "LOSS_FUNCTION = {\n",
    "    \"bce\": nn.BCEWithLogitsLoss(),\n",
    "    \"dice\": losses.DiceLoss(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, eval_loader, loss_function=nn.BCEWithLogitsLoss(), device=\"cuda\"):\n",
    "    # model.eval()\n",
    "    # torch.set_grad_enabled(False)\n",
    "\n",
    "    total_eval_loss = 0\n",
    "    epoch_eval_pred, epoch_eval_target = torch.Tensor().to(device), torch.IntTensor().to(device)\n",
    "    \n",
    "    with tqdm(eval_loader, unit=\"batch\", position=0, leave=True) as batch:\n",
    "        for i, (data, target) in enumerate(batch):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            output = model(data)\n",
    "            predictions = torch.sigmoid(output)\n",
    "            epoch_eval_pred = torch.cat((epoch_eval_pred, predictions), dim=0)\n",
    "            epoch_eval_target = torch.cat((epoch_eval_target, target), dim=0)\n",
    "\n",
    "            # Evaluate on eval set\n",
    "            eval_results = compute_metrics(epoch_eval_pred, epoch_eval_target.int())\n",
    "            \n",
    "            loss = loss_function(output, target.float())\n",
    "            total_eval_loss += loss.item()  # sum up batch loss\n",
    "\n",
    "            batch.set_postfix_str(\"EVAL LOSS:{:.4f} EVAL_METRICS:{}\".format(\n",
    "                total_eval_loss/(i+1), eval_results))\n",
    "    \n",
    "    return {\n",
    "        \"total_loss\": total_eval_loss,\n",
    "        \"iter\": i+1,\n",
    "        \"eval_metrics\": eval_results,\n",
    "        \"predictions\": epoch_eval_pred,\n",
    "        \"targets\": epoch_eval_target,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, device=\"cuda\", loss_function=nn.BCEWithLogitsLoss(), reduce_lr_on_plateau=True, early_stop=5, max_num_epochs=5, max_norm=10.0, log_interval=1):\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    if reduce_lr_on_plateau:\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, \"min\")\n",
    "\n",
    "    result_log = {\n",
    "        \"train_loss\": [],\n",
    "        \"valid_loss\": [],\n",
    "        \"max_num_epochs\": max_num_epochs,\n",
    "        \"valid__preds\": [],\n",
    "        \"valid__gts\": [],\n",
    "    }\n",
    "    count_stop = 0\n",
    "\n",
    "    for epoch in range(max_num_epochs):\n",
    "        model.train()\n",
    "        torch.set_grad_enabled(True)\n",
    "        total_train_loss = 0\n",
    "        epoch_train_pred, epoch_train_target = torch.Tensor().to(device), torch.Tensor().to(device)\n",
    "        with tqdm(train_loader, unit=\"batch\", position=0, leave=True) as batch:\n",
    "            for i, (data, target) in enumerate(batch):\n",
    "                batch.set_postfix_str(f\"(Epoch {epoch})\")\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                output = model(data)\n",
    "                predictions = torch.sigmoid(output)\n",
    "                epoch_train_pred = torch.cat((epoch_train_pred, predictions), dim=0)\n",
    "                epoch_train_target = torch.cat((epoch_train_target, target), dim=0)\n",
    "\n",
    "                # Evaluate on train set\n",
    "                batch.set_postfix_str(f\"(Epoch {epoch}) EVALUATING...\")\n",
    "                train_eval_results = compute_metrics(epoch_train_pred, epoch_train_target.int())\n",
    "                \n",
    "                loss = loss_function(output, target.float())\n",
    "                # Scales the loss, and calls backward() to create scaled gradients\n",
    "                scaler.scale(loss).backward()\n",
    "                # Unscales the gradients of optimizer's assigned params in-place\n",
    "                scaler.unscale_(optimizer)\n",
    "                # Since the gradients of optimizer's assigned params are unscaled, clips as usual:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n",
    "                # Unscales gradients and calls optimizer.step()\n",
    "                scaler.step(optimizer)\n",
    "                # Updates the scale for next iteration\n",
    "                scaler.update()\n",
    "\n",
    "                train_loss = loss.item()\n",
    "                total_train_loss += train_loss\n",
    "                batch.set_postfix_str(\"(Epoch {}) TRAIN LOSS:{:.4f} LR:{:.8f} TRAIN_EVAL:{}\".format((epoch+1),\n",
    "                total_train_loss/(i+1), get_lr(optimizer), train_eval_results))\n",
    "\n",
    "            result_log[\"train_loss\"].append(total_train_loss/(i+1))\n",
    "            for k in train_eval_results.keys():    \n",
    "                if result_log.get(f\"train__{k}\") is None:\n",
    "                    result_log[f\"train__{k}\"] = []\n",
    "                result_log[f\"train__{k}\"].append(train_eval_results[k])\n",
    "                \n",
    "            if epoch % log_interval == 0:\n",
    "                avg_train_loss = total_train_loss\n",
    "                # Evaluate on valid set\n",
    "                valid_eval_results = evaluate(model, train_loader, loss_function=loss_function, device=device)\n",
    "                result_log[\"valid_loss\"].append(valid_eval_results[\"total_loss\"]/valid_eval_results[\"iter\"])\n",
    "                for k in valid_eval_results[\"eval_metrics\"].keys():    \n",
    "                    if result_log.get(f\"valid__{k}\") is None:\n",
    "                        result_log[f\"valid__{k}\"] = []\n",
    "                    result_log[f\"valid__{k}\"].append(valid_eval_results[\"eval_metrics\"][k])\n",
    "                result_log[\"valid__preds\"].append(valid_eval_results[\"predictions\"])\n",
    "                result_log[\"valid__gts\"].append(valid_eval_results[\"targets\"])\n",
    "\n",
    "            # Early stopping\n",
    "            if min(result_log[\"valid_loss\"]) < result_log[\"valid_loss\"][-1]:\n",
    "                count_stop = 0\n",
    "            else:\n",
    "                count_stop += 1\n",
    "                if count_stop == early_stop:\n",
    "                    break\n",
    "    result_log[\"num_epochs\"] = epoch + 1\n",
    "    return model, result_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(in_channels=112,\n",
    "             out_channels=112,\n",
    "             n_blocks=4,\n",
    "             start_filters=32,\n",
    "             activation='relu',\n",
    "             normalization='batch',\n",
    "             conv_mode='same',\n",
    "             dim=2)\n",
    "model = model.cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "model, result_log = train(model, train_loader, optimizer, loss_function=losses.DiceLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_log[\"train__dice\"], result_log[\"valid__dice\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_axis = range(result_log[\"num_epochs\"])\n",
    "plt.plot(epoch_axis, result_log[\"train_loss\"], 'g', label='Training loss')\n",
    "plt.plot(epoch_axis, result_log[\"valid_loss\"], 'b', label='Validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_log.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(result_log[\"valid__preds\"][0][:, :, 40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(result_log[\"valid__gts\"][0][:, :, 40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21041/3770023701.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = datasets.load_metric(\"accuracy\")\n"
     ]
    }
   ],
   "source": [
    "metric = datasets.load_metric(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def problem2_load_dataset(manifest_path, img_dir_path, img_column_name=\"image_train\", label_column_name=\"label_train\"):\n",
    "    manifest_df = pd.read_csv(manifest_path)\n",
    "    manifest_df[img_column_name] = img_dir_path + manifest_df[img_column_name].astype(str)\n",
    "    manifest_df = manifest_df.rename(columns={img_column_name: \"image\", label_column_name: \"label\"})\n",
    "    dataset = datasets.Dataset.from_pandas(manifest_df)\n",
    "    dataset = dataset.cast_column(\"image\", datasets.Image(decode=True))\n",
    "    dataset = dataset.class_encode_column(\"label\")\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "def0791d12854848813d282ddeec703a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stringifying the column:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02daffa95f134a12a2790c087da5b8f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aab030d70dd4dcaa69aa6aaaa546bf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49c015ac83154f33b272271dd9580f69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Stringifying the column:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cde8503acd940a3ba7292245be59c17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting to class labels:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d65588a642ea41a1aadb7332d9e65c9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_datasets = datasets.DatasetDict()\n",
    "train_val_dataset = problem2_load_dataset(\"./data/problem2_datas/annotation/train.csv\", \"./data/problem2_datas/images/\").train_test_split(test_size=0.2)\n",
    "raw_datasets[\"train\"] = train_val_dataset[\"train\"]\n",
    "raw_datasets[\"valid\"] = train_val_dataset[\"test\"]\n",
    "raw_datasets[\"test\"] = problem2_load_dataset(\"./data/problem2_datas/annotation/test.csv\", \"./data/problem2_datas/images/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"microsoft/resnet-50\")\n",
    "model = AutoModelForImageClassification.from_pretrained(\"microsoft/resnet-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = Normalize(mean=feature_extractor.image_mean, std=feature_extractor.image_std)\n",
    "train_transforms = Compose(\n",
    "        [\n",
    "            RandomResizedCrop(feature_extractor.size),\n",
    "            RandomHorizontalFlip(),\n",
    "            ToTensor(),\n",
    "            normalize,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "eval_transforms = Compose(\n",
    "        [\n",
    "            Resize(feature_extractor.size),\n",
    "            CenterCrop(feature_extractor.size),\n",
    "            ToTensor(),\n",
    "            normalize,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def preprocess_train(example_batch):\n",
    "    \"\"\"Apply train_transforms across a batch.\"\"\"\n",
    "    example_batch[\"pixel_values\"] = [\n",
    "        train_transforms(image.convert(\"RGB\")) for image in example_batch[\"image\"]\n",
    "    ]\n",
    "    return example_batch\n",
    "\n",
    "def preprocess_eval(example_batch):\n",
    "    \"\"\"Apply eval_transforms across a batch.\"\"\"\n",
    "    example_batch[\"pixel_values\"] = [\n",
    "        eval_transforms(image.convert(\"RGB\")) for image in example_batch[\"image\"]\n",
    "    ]\n",
    "    return example_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_datasets = raw_datasets\n",
    "proc_datasets[\"train\"].set_transform(preprocess_train)\n",
    "proc_datasets[\"valid\"].set_transform(preprocess_eval)\n",
    "proc_datasets[\"test\"].set_transform(preprocess_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"test\"\n",
    "\n",
    "args = TrainingArguments(\n",
    "    f\"problem2-{model_name}\",\n",
    "    remove_unused_columns=False,\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    gradient_accumulation_steps=1,\n",
    "    eval_accumulation_steps=1,\n",
    "    per_device_eval_batch_size=32,\n",
    "    num_train_epochs=100,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=1,\n",
    "    save_steps=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    greater_is_better=True,\n",
    "    push_to_hub=True,\n",
    "    logging_strategy=\"epoch\",\n",
    "    gradient_checkpointing=True,\n",
    "    fp16=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Computes accuracy on a batch of predictions\"\"\"\n",
    "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=eval_pred.label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(examples):\n",
    "    pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n",
    "    labels = torch.tensor([example[\"label\"] for example in examples])\n",
    "    return {\"pixel_values\": pixel_values, \"labels\": labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/holy/projects/ai-healthcare/assignment1/problem2-test is already a clone of https://huggingface.co/holylovenia/problem2-test. Make sure you pull the latest changes with `repo.git_pull()`.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=proc_datasets[\"train\"],\n",
    "    eval_dataset=proc_datasets[\"valid\"],\n",
    "    tokenizer=feature_extractor,\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/holy/anaconda3/envs/health/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 244\n",
      "  Num Epochs = 100\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 4\n",
      "  Total optimization steps = 700\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='134' max='700' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [134/700 03:04 < 13:13, 0.71 it/s, Epoch 18.90/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>9.218000</td>\n",
       "      <td>11.299341</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>9.281400</td>\n",
       "      <td>13.703536</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>9.176200</td>\n",
       "      <td>12.781616</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9.161100</td>\n",
       "      <td>11.861242</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>8.894800</td>\n",
       "      <td>12.200876</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>8.908300</td>\n",
       "      <td>10.398988</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>8.719500</td>\n",
       "      <td>9.302373</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>8.438200</td>\n",
       "      <td>12.773362</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>8.172500</td>\n",
       "      <td>11.968035</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>8.079100</td>\n",
       "      <td>11.749663</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>7.712800</td>\n",
       "      <td>7.429304</td>\n",
       "      <td>0.016393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>7.451800</td>\n",
       "      <td>8.631205</td>\n",
       "      <td>0.016393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>7.166300</td>\n",
       "      <td>9.766940</td>\n",
       "      <td>0.016393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>6.992700</td>\n",
       "      <td>8.373461</td>\n",
       "      <td>0.081967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>6.777600</td>\n",
       "      <td>7.749249</td>\n",
       "      <td>0.098361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>6.375400</td>\n",
       "      <td>7.246853</td>\n",
       "      <td>0.098361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>6.195700</td>\n",
       "      <td>8.038286</td>\n",
       "      <td>0.114754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>5.900600</td>\n",
       "      <td>6.150668</td>\n",
       "      <td>0.131148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>5.678400</td>\n",
       "      <td>8.717762</td>\n",
       "      <td>0.213115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to problem2-test/checkpoint-7\n",
      "Configuration saved in problem2-test/checkpoint-7/config.json\n",
      "Model weights saved in problem2-test/checkpoint-7/pytorch_model.bin\n",
      "Feature extractor saved in problem2-test/checkpoint-7/preprocessor_config.json\n",
      "Feature extractor saved in problem2-test/preprocessor_config.json\n",
      "Several commits (2) will be pushed upstream.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to problem2-test/checkpoint-14\n",
      "Configuration saved in problem2-test/checkpoint-14/config.json\n",
      "Model weights saved in problem2-test/checkpoint-14/pytorch_model.bin\n",
      "Feature extractor saved in problem2-test/checkpoint-14/preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to problem2-test/checkpoint-21\n",
      "Configuration saved in problem2-test/checkpoint-21/config.json\n",
      "Model weights saved in problem2-test/checkpoint-21/pytorch_model.bin\n",
      "Feature extractor saved in problem2-test/checkpoint-21/preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to problem2-test/checkpoint-28\n",
      "Configuration saved in problem2-test/checkpoint-28/config.json\n",
      "Model weights saved in problem2-test/checkpoint-28/pytorch_model.bin\n",
      "Feature extractor saved in problem2-test/checkpoint-28/preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to problem2-test/checkpoint-35\n",
      "Configuration saved in problem2-test/checkpoint-35/config.json\n",
      "Model weights saved in problem2-test/checkpoint-35/pytorch_model.bin\n",
      "Feature extractor saved in problem2-test/checkpoint-35/preprocessor_config.json\n",
      "Feature extractor saved in problem2-test/preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to problem2-test/checkpoint-42\n",
      "Configuration saved in problem2-test/checkpoint-42/config.json\n",
      "Model weights saved in problem2-test/checkpoint-42/pytorch_model.bin\n",
      "Feature extractor saved in problem2-test/checkpoint-42/preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to problem2-test/checkpoint-49\n",
      "Configuration saved in problem2-test/checkpoint-49/config.json\n",
      "Model weights saved in problem2-test/checkpoint-49/pytorch_model.bin\n",
      "Feature extractor saved in problem2-test/checkpoint-49/preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to problem2-test/checkpoint-56\n",
      "Configuration saved in problem2-test/checkpoint-56/config.json\n",
      "Model weights saved in problem2-test/checkpoint-56/pytorch_model.bin\n",
      "Feature extractor saved in problem2-test/checkpoint-56/preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to problem2-test/checkpoint-63\n",
      "Configuration saved in problem2-test/checkpoint-63/config.json\n",
      "Model weights saved in problem2-test/checkpoint-63/pytorch_model.bin\n",
      "Feature extractor saved in problem2-test/checkpoint-63/preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to problem2-test/checkpoint-70\n",
      "Configuration saved in problem2-test/checkpoint-70/config.json\n",
      "Model weights saved in problem2-test/checkpoint-70/pytorch_model.bin\n",
      "Feature extractor saved in problem2-test/checkpoint-70/preprocessor_config.json\n",
      "Feature extractor saved in problem2-test/preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to problem2-test/checkpoint-77\n",
      "Configuration saved in problem2-test/checkpoint-77/config.json\n",
      "Model weights saved in problem2-test/checkpoint-77/pytorch_model.bin\n",
      "Feature extractor saved in problem2-test/checkpoint-77/preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to problem2-test/checkpoint-84\n",
      "Configuration saved in problem2-test/checkpoint-84/config.json\n",
      "Model weights saved in problem2-test/checkpoint-84/pytorch_model.bin\n",
      "Feature extractor saved in problem2-test/checkpoint-84/preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to problem2-test/checkpoint-91\n",
      "Configuration saved in problem2-test/checkpoint-91/config.json\n",
      "Model weights saved in problem2-test/checkpoint-91/pytorch_model.bin\n",
      "Feature extractor saved in problem2-test/checkpoint-91/preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to problem2-test/checkpoint-98\n",
      "Configuration saved in problem2-test/checkpoint-98/config.json\n",
      "Model weights saved in problem2-test/checkpoint-98/pytorch_model.bin\n",
      "Feature extractor saved in problem2-test/checkpoint-98/preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to problem2-test/checkpoint-105\n",
      "Configuration saved in problem2-test/checkpoint-105/config.json\n",
      "Model weights saved in problem2-test/checkpoint-105/pytorch_model.bin\n",
      "Feature extractor saved in problem2-test/checkpoint-105/preprocessor_config.json\n",
      "Feature extractor saved in problem2-test/preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to problem2-test/checkpoint-112\n",
      "Configuration saved in problem2-test/checkpoint-112/config.json\n",
      "Model weights saved in problem2-test/checkpoint-112/pytorch_model.bin\n",
      "Feature extractor saved in problem2-test/checkpoint-112/preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to problem2-test/checkpoint-119\n",
      "Configuration saved in problem2-test/checkpoint-119/config.json\n",
      "Model weights saved in problem2-test/checkpoint-119/pytorch_model.bin\n",
      "Feature extractor saved in problem2-test/checkpoint-119/preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to problem2-test/checkpoint-126\n",
      "Configuration saved in problem2-test/checkpoint-126/config.json\n",
      "Model weights saved in problem2-test/checkpoint-126/pytorch_model.bin\n",
      "Feature extractor saved in problem2-test/checkpoint-126/preprocessor_config.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 61\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to problem2-test/checkpoint-133\n",
      "Configuration saved in problem2-test/checkpoint-133/config.json\n",
      "Model weights saved in problem2-test/checkpoint-133/pytorch_model.bin\n",
      "Feature extractor saved in problem2-test/checkpoint-133/preprocessor_config.json\n",
      "Feature extractor saved in problem2-test/preprocessor_config.json\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_results \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# rest is optional but nice to have\u001b[39;00m\n\u001b[1;32m      3\u001b[0m trainer\u001b[38;5;241m.\u001b[39msave_model()\n",
      "File \u001b[0;32m~/anaconda3/envs/health/lib/python3.10/site-packages/transformers/trainer.py:1500\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1495\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m   1497\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1498\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1499\u001b[0m )\n\u001b[0;32m-> 1500\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/health/lib/python3.10/site-packages/transformers/trainer.py:1834\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1831\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_training_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1833\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_epoch_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 1834\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1836\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DebugOption\u001b[38;5;241m.\u001b[39mTPU_METRICS_DEBUG \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdebug:\n\u001b[1;32m   1837\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_torch_tpu_available():\n\u001b[1;32m   1838\u001b[0m         \u001b[38;5;66;03m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/health/lib/python3.10/site-packages/transformers/trainer.py:2056\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2053\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step, metrics)\n\u001b[1;32m   2055\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[0;32m-> 2056\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2057\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_save(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m~/anaconda3/envs/health/lib/python3.10/site-packages/transformers/trainer.py:2215\u001b[0m, in \u001b[0;36mTrainer._save_checkpoint\u001b[0;34m(self, model, trial, metrics)\u001b[0m\n\u001b[1;32m   2212\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(rng_states, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrng_state_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mprocess_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   2214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpush_to_hub:\n\u001b[0;32m-> 2215\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_push_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2217\u001b[0m \u001b[38;5;66;03m# Maybe delete some older checkpoints.\u001b[39;00m\n\u001b[1;32m   2218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mshould_save:\n",
      "File \u001b[0;32m~/anaconda3/envs/health/lib/python3.10/site-packages/transformers/trainer.py:3382\u001b[0m, in \u001b[0;36mTrainer._push_from_checkpoint\u001b[0;34m(self, checkpoint_folder)\u001b[0m\n\u001b[1;32m   3380\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3381\u001b[0m         commit_message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining in progress, epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mepoch)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 3382\u001b[0m     _, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpush_in_progress \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpush_to_hub\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcommit_message\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_message\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauto_lfs_prune\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m   3384\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3385\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   3386\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mhub_strategy \u001b[38;5;241m==\u001b[39m HubStrategy\u001b[38;5;241m.\u001b[39mCHECKPOINT:\n\u001b[1;32m   3387\u001b[0m         \u001b[38;5;66;03m# Move back the checkpoint to its place\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/health/lib/python3.10/site-packages/huggingface_hub/repository.py:1436\u001b[0m, in \u001b[0;36mRepository.push_to_hub\u001b[0;34m(self, commit_message, blocking, clean_ok, auto_lfs_prune)\u001b[0m\n\u001b[1;32m   1434\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo currently clean. Ignoring push_to_hub\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1435\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1436\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgit_add\u001b[49m\u001b[43m(\u001b[49m\u001b[43mauto_lfs_track\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1437\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgit_commit(commit_message)\n\u001b[1;32m   1438\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgit_push(\n\u001b[1;32m   1439\u001b[0m     upstream\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morigin \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_branch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1440\u001b[0m     blocking\u001b[38;5;241m=\u001b[39mblocking,\n\u001b[1;32m   1441\u001b[0m     auto_lfs_prune\u001b[38;5;241m=\u001b[39mauto_lfs_prune,\n\u001b[1;32m   1442\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/health/lib/python3.10/site-packages/huggingface_hub/repository.py:1116\u001b[0m, in \u001b[0;36mRepository.git_add\u001b[0;34m(self, pattern, auto_lfs_track)\u001b[0m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1101\u001b[0m \u001b[38;5;124;03mgit add\u001b[39;00m\n\u001b[1;32m   1102\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1112\u001b[0m \u001b[38;5;124;03m        be automatically tracked.\u001b[39;00m\n\u001b[1;32m   1113\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m auto_lfs_track:\n\u001b[1;32m   1115\u001b[0m     \u001b[38;5;66;03m# Track files according to their size (>=10MB)\u001b[39;00m\n\u001b[0;32m-> 1116\u001b[0m     tracked_files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauto_track_large_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;66;03m# Read the remaining files and track them if they're binary\u001b[39;00m\n\u001b[1;32m   1119\u001b[0m     tracked_files\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_track_binary_files(pattern))\n",
      "File \u001b[0;32m~/anaconda3/envs/health/lib/python3.10/site-packages/huggingface_hub/repository.py:1024\u001b[0m, in \u001b[0;36mRepository.auto_track_large_files\u001b[0;34m(self, pattern)\u001b[0m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;124;03mAutomatically track large files (files that weigh more than 10MBs) with\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m \u001b[38;5;124;03mgit-lfs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;124;03m    size.\u001b[39;00m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m files_to_be_tracked_with_lfs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 1024\u001b[0m deleted_files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_deleted_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m files_to_be_staged(pattern, folder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocal_dir):\n\u001b[1;32m   1027\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m deleted_files:\n",
      "File \u001b[0;32m~/anaconda3/envs/health/lib/python3.10/site-packages/huggingface_hub/repository.py:879\u001b[0m, in \u001b[0;36mRepository.list_deleted_files\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    870\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;124;03mReturns a list of the files that are deleted in the working directory or\u001b[39;00m\n\u001b[1;32m    872\u001b[0m \u001b[38;5;124;03mindex.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;124;03m    directory or index.\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 879\u001b[0m     git_status \u001b[38;5;241m=\u001b[39m \u001b[43mrun_subprocess\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgit status -s\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocal_dir\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m    882\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    883\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(exc\u001b[38;5;241m.\u001b[39mstderr)\n",
      "File \u001b[0;32m~/anaconda3/envs/health/lib/python3.10/site-packages/huggingface_hub/utils/_subprocess.py:52\u001b[0m, in \u001b[0;36mrun_subprocess\u001b[0;34m(command, folder, check, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(command, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     50\u001b[0m     command \u001b[38;5;241m=\u001b[39m command\u001b[38;5;241m.\u001b[39msplit()\n\u001b[0;32m---> 52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstderr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcwd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfolder\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetcwd\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/health/lib/python3.10/subprocess.py:503\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    502\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 503\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    505\u001b[0m         process\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[0;32m~/anaconda3/envs/health/lib/python3.10/subprocess.py:1152\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1151\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1152\u001b[0m     stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_communicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1154\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1155\u001b[0m     \u001b[38;5;66;03m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[1;32m   1156\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/health/lib/python3.10/subprocess.py:2003\u001b[0m, in \u001b[0;36mPopen._communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   1996\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timeout(endtime, orig_timeout,\n\u001b[1;32m   1997\u001b[0m                         stdout, stderr,\n\u001b[1;32m   1998\u001b[0m                         skip_check_and_raise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1999\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(  \u001b[38;5;66;03m# Impossible :)\u001b[39;00m\n\u001b[1;32m   2000\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_check_timeout(..., skip_check_and_raise=True) \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2001\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfailed to raise TimeoutExpired.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 2003\u001b[0m ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timeout(endtime, orig_timeout, stdout, stderr)\n\u001b[1;32m   2006\u001b[0m \u001b[38;5;66;03m# XXX Rewrite these to use non-blocking I/O on the file\u001b[39;00m\n\u001b[1;32m   2007\u001b[0m \u001b[38;5;66;03m# objects; they are no longer using C stdio!\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/health/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_results = trainer.train()\n",
    "# rest is optional but nice to have\n",
    "trainer.save_model()\n",
    "trainer.log_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = trainer.evaluate()\n",
    "# some nice to haves:\n",
    "trainer.log_metrics(\"valid\", metrics)\n",
    "trainer.save_metrics(\"valid\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = trainer.evaluate(proc_datasets[\"test\"])\n",
    "# some nice to haves:\n",
    "trainer.log_metrics(\"test\", metrics)\n",
    "trainer.save_metrics(\"test\", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "d2f67f6f02098114f1eb667dbde229539e133e34a85b887b9dc3eea951e127e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
