{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ELEC6910X Advanced Topics in AI and Healthcare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Holy Lovenia - 20814158***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from pytorch3dunet.unet3d import losses\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import init\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from tqdm import tqdm\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import surface_distance.metrics as sf\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchio as tio\n",
    "import torchmetrics\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "\n",
    "def set_all_seeds(seed):\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  torch.manual_seed(seed)\n",
    "  torch.cuda.manual_seed(seed)\n",
    "  torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_all_seeds(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem, you are required to implement a 3D segmentation network (e.g., 3d unet), including\n",
    "the model, dataloader, training/testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Problem1Dataset(Dataset):\n",
    "    def __init__(self, dir_path, column_names=[\"image\", \"label\"], resize_type=\"center\", resize_target_shape=(112, 112, 88), transform=None, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.dir_path = dir_path\n",
    "        self.column_names = column_names\n",
    "        self.transform = transform\n",
    "        self.resize_type = resize_type\n",
    "        self.resize_target_shape = resize_target_shape\n",
    "        self._init_transform_methods()\n",
    "        self._load_all_data_from_dir(dir_path)\n",
    "    \n",
    "    def _load_h5_data(self, file_path):\n",
    "        hf = h5py.File(file_path, \"r\")\n",
    "        return hf\n",
    "\n",
    "    def _load_all_data_from_dir(self, dir_path):\n",
    "        df_dict = {}\n",
    "        for col in self.column_names:\n",
    "            df_dict[col] = []\n",
    "\n",
    "        for file_name in os.listdir(dir_path):\n",
    "            file_path = os.path.join(dir_path, file_name)\n",
    "            if os.path.isfile(file_path) and file_path.endswith(\".h5\"):\n",
    "                data = self._load_h5_data(file_path)\n",
    "                for col in self.column_names:\n",
    "                    df_dict[col] += [np.array(data[col][:])]\n",
    "        self.dataset = pd.DataFrame.from_dict(df_dict)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        current_data = self.dataset.iloc[index]\n",
    "        transformed = self.set_transform(current_data[\"image\"], current_data[\"label\"])\n",
    "        return transformed\n",
    "\n",
    "    def _init_transform_methods(self):\n",
    "        self._random_affine = tio.RandomAffine(scales=(0.9, 1.2), degrees=15)\n",
    "        self._random_motion = tio.RandomMotion()\n",
    "        self._random_elastic_deformation = tio.RandomElasticDeformation()\n",
    "        self._random_blur = tio.RandomBlur()\n",
    "        self._random_transform = tio.OneOf({\n",
    "            self._random_affine: 0.25,\n",
    "            self._random_motion: 0.25,\n",
    "            self._random_elastic_deformation: 0.25,\n",
    "            self._random_blur: 0.25,\n",
    "        })\n",
    "        self._random_double = tio.Compose([self._random_transform, self._random_transform])\n",
    "        self._crop_or_pad = tio.CropOrPad(self.resize_target_shape)\n",
    "\n",
    "    def set_transform(self, data, label):\n",
    "        transformed_data, transformed_label = self.resize(data, label)\n",
    "\n",
    "        if self.transform is None:\n",
    "            return transformed_data, transformed_label\n",
    "        else:\n",
    "            if self.transform == \"random\":\n",
    "                transform_method = self._random_transform\n",
    "            elif self.transform == \"motion\":\n",
    "                transform_method = self._random_motion\n",
    "            elif self.transform == \"affine\":\n",
    "                transform_method = self._random_affine\n",
    "            elif self.transform == \"elastic_deformation\":\n",
    "                transform_method = self._random_elastic_deformation\n",
    "            elif self.transform == \"random_double\":\n",
    "                transform_method = self._random_double\n",
    "\n",
    "            transformed_data = np.expand_dims(transformed_data, axis=0)\n",
    "            transformed_data = transform_method(transformed_data)\n",
    "            transformed_data = np.squeeze(transformed_data, axis=0)\n",
    "\n",
    "            transformed_label = np.expand_dims(transformed_label, axis=0)\n",
    "            transformed_label = transform_method(transformed_label)\n",
    "            transformed_label = np.squeeze(transformed_label, axis=0)\n",
    "\n",
    "            return transformed_data, transformed_label\n",
    "\n",
    "    def resize(self, data, label):\n",
    "        if self.resize_type == \"center\":\n",
    "            transformed_data = np.expand_dims(data, axis=0)\n",
    "            transformed_data = self._crop_or_pad(transformed_data)\n",
    "            transformed_data = np.squeeze(transformed_data, axis=0)\n",
    "            transformed_label = np.expand_dims(label, axis=0)\n",
    "            transformed_label = self._crop_or_pad(transformed_label)\n",
    "            transformed_label = np.squeeze(transformed_label, axis=0)\n",
    "            return transformed_data, transformed_label\n",
    "        elif self.resize_type == \"random\":\n",
    "            return get_random_crop(data, label, crop_width=self.resize_target_shape[0], crop_height=self.resize_target_shape[1])\n",
    "\n",
    "def get_random_crop(data, label, crop_width, crop_height):\n",
    "    max_w = data.shape[1] - crop_width\n",
    "    max_h = data.shape[0] - crop_height\n",
    "    w = np.random.randint(0, max_w)\n",
    "    h = np.random.randint(0, max_h)\n",
    "    cropped_data = data[h: h + crop_height, w: w + crop_width, :]\n",
    "    cropped_label = label[h: h + crop_height, w: w + crop_width, :]\n",
    "    return cropped_data, cropped_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Problem1Dataset(\"./data/problem1_datas/train\", resize_type=\"random\", resize_target_shape=(112, 112, 88), transform=\"random\")\n",
    "valid_dataset = Problem1Dataset(\"./data/problem1_datas/train\", resize_type=\"center\", resize_target_shape=(112, 112, 88), transform=None)\n",
    "test_dataset = Problem1Dataset(\"./data/problem1_datas/test\", resize_type=\"center\", resize_target_shape=(112, 112, 88), transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=14, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=14, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=14, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "\n",
    "@torch.jit.script\n",
    "def autocrop(encoder_layer: torch.Tensor, decoder_layer: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Center-crops the encoder_layer to the size of the decoder_layer,\n",
    "    so that merging (concatenation) between levels/blocks is possible.\n",
    "    This is only necessary for input sizes != 2**n for 'same' padding and always required for 'valid' padding.\n",
    "    \"\"\"\n",
    "    if encoder_layer.shape[2:] != decoder_layer.shape[2:]:\n",
    "        ds = encoder_layer.shape[2:]\n",
    "        es = decoder_layer.shape[2:]\n",
    "        assert ds[0] >= es[0]\n",
    "        assert ds[1] >= es[1]\n",
    "        if encoder_layer.dim() == 4:  # 2D\n",
    "            encoder_layer = encoder_layer[\n",
    "                            :,\n",
    "                            :,\n",
    "                            ((ds[0] - es[0]) // 2):((ds[0] + es[0]) // 2),\n",
    "                            ((ds[1] - es[1]) // 2):((ds[1] + es[1]) // 2)\n",
    "                            ]\n",
    "        elif encoder_layer.dim() == 5:  # 3D\n",
    "            assert ds[2] >= es[2]\n",
    "            encoder_layer = encoder_layer[\n",
    "                            :,\n",
    "                            :,\n",
    "                            ((ds[0] - es[0]) // 2):((ds[0] + es[0]) // 2),\n",
    "                            ((ds[1] - es[1]) // 2):((ds[1] + es[1]) // 2),\n",
    "                            ((ds[2] - es[2]) // 2):((ds[2] + es[2]) // 2),\n",
    "                            ]\n",
    "    return encoder_layer, decoder_layer\n",
    "\n",
    "\n",
    "def conv_layer(dim: int):\n",
    "    if dim == 3:\n",
    "        return nn.Conv3d\n",
    "    elif dim == 2:\n",
    "        return nn.Conv2d\n",
    "\n",
    "\n",
    "def get_conv_layer(in_channels: int,\n",
    "                   out_channels: int,\n",
    "                   kernel_size: int = 3,\n",
    "                   stride: int = 1,\n",
    "                   padding: int = 1,\n",
    "                   bias: bool = True,\n",
    "                   dim: int = 2):\n",
    "    return conv_layer(dim)(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding,\n",
    "                           bias=bias)\n",
    "\n",
    "\n",
    "def conv_transpose_layer(dim: int):\n",
    "    if dim == 3:\n",
    "        return nn.ConvTranspose3d\n",
    "    elif dim == 2:\n",
    "        return nn.ConvTranspose2d\n",
    "\n",
    "\n",
    "def get_up_layer(in_channels: int,\n",
    "                 out_channels: int,\n",
    "                 kernel_size: int = 2,\n",
    "                 stride: int = 2,\n",
    "                 dim: int = 3,\n",
    "                 up_mode: str = 'transposed',\n",
    "                 ):\n",
    "    if up_mode == 'transposed':\n",
    "        return conv_transpose_layer(dim)(in_channels, out_channels, kernel_size=kernel_size, stride=stride)\n",
    "    else:\n",
    "        return nn.Upsample(scale_factor=2.0, mode=up_mode)\n",
    "\n",
    "\n",
    "def maxpool_layer(dim: int):\n",
    "    if dim == 3:\n",
    "        return nn.MaxPool3d\n",
    "    elif dim == 2:\n",
    "        return nn.MaxPool2d\n",
    "\n",
    "\n",
    "def get_maxpool_layer(kernel_size: int = 2,\n",
    "                      stride: int = 2,\n",
    "                      padding: int = 0,\n",
    "                      dim: int = 2):\n",
    "    return maxpool_layer(dim=dim)(kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "\n",
    "\n",
    "def get_activation(activation: str):\n",
    "    if activation == 'relu':\n",
    "        return nn.ReLU()\n",
    "    elif activation == 'leaky':\n",
    "        return nn.LeakyReLU(negative_slope=0.1)\n",
    "    elif activation == 'elu':\n",
    "        return nn.ELU()\n",
    "\n",
    "\n",
    "def get_normalization(normalization: str,\n",
    "                      num_channels: int,\n",
    "                      dim: int):\n",
    "    if normalization == 'batch':\n",
    "        if dim == 3:\n",
    "            return nn.BatchNorm3d(num_channels)\n",
    "        elif dim == 2:\n",
    "            return nn.BatchNorm2d(num_channels)\n",
    "    elif normalization == 'instance':\n",
    "        if dim == 3:\n",
    "            return nn.InstanceNorm3d(num_channels)\n",
    "        elif dim == 2:\n",
    "            return nn.InstanceNorm2d(num_channels)\n",
    "    elif 'group' in normalization:\n",
    "        num_groups = int(normalization.partition('group')[-1])  # get the group size from string\n",
    "        return nn.GroupNorm(num_groups=num_groups, num_channels=num_channels)\n",
    "\n",
    "\n",
    "class Concatenate(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Concatenate, self).__init__()\n",
    "\n",
    "    def forward(self, layer_1, layer_2):\n",
    "        x = torch.cat((layer_1, layer_2), 1)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DownBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    A helper Module that performs 2 Convolutions and 1 MaxPool.\n",
    "    An activation follows each convolution.\n",
    "    A normalization layer follows each convolution.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 out_channels: int,\n",
    "                 pooling: bool = True,\n",
    "                 activation: str = 'relu',\n",
    "                 normalization: str = None,\n",
    "                 dim: str = 2,\n",
    "                 conv_mode: str = 'same'):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.pooling = pooling\n",
    "        self.normalization = normalization\n",
    "        if conv_mode == 'same':\n",
    "            self.padding = 1\n",
    "        elif conv_mode == 'valid':\n",
    "            self.padding = 0\n",
    "        self.dim = dim\n",
    "        self.activation = activation\n",
    "\n",
    "        # conv layers\n",
    "        self.conv1 = get_conv_layer(self.in_channels, self.out_channels, kernel_size=3, stride=1, padding=self.padding,\n",
    "                                    bias=True, dim=self.dim)\n",
    "        self.conv2 = get_conv_layer(self.out_channels, self.out_channels, kernel_size=3, stride=1, padding=self.padding,\n",
    "                                    bias=True, dim=self.dim)\n",
    "\n",
    "        # pooling layer\n",
    "        if self.pooling:\n",
    "            self.pool = get_maxpool_layer(kernel_size=2, stride=2, padding=0, dim=self.dim)\n",
    "\n",
    "        # activation layers\n",
    "        self.act1 = get_activation(self.activation)\n",
    "        self.act2 = get_activation(self.activation)\n",
    "\n",
    "        # normalization layers\n",
    "        if self.normalization:\n",
    "            self.norm1 = get_normalization(normalization=self.normalization, num_channels=self.out_channels,\n",
    "                                           dim=self.dim)\n",
    "            self.norm2 = get_normalization(normalization=self.normalization, num_channels=self.out_channels,\n",
    "                                           dim=self.dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.conv1(x)  # convolution 1\n",
    "        y = self.act1(y)  # activation 1\n",
    "        if self.normalization:\n",
    "            y = self.norm1(y)  # normalization 1\n",
    "        y = self.conv2(y)  # convolution 2\n",
    "        y = self.act2(y)  # activation 2\n",
    "        if self.normalization:\n",
    "            y = self.norm2(y)  # normalization 2\n",
    "\n",
    "        before_pooling = y  # save the outputs before the pooling operation\n",
    "        if self.pooling:\n",
    "            y = self.pool(y)  # pooling\n",
    "        return y, before_pooling\n",
    "\n",
    "\n",
    "class UpBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    A helper Module that performs 2 Convolutions and 1 UpConvolution/Upsample.\n",
    "    An activation follows each convolution.\n",
    "    A normalization layer follows each convolution.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 out_channels: int,\n",
    "                 activation: str = 'relu',\n",
    "                 normalization: str = None,\n",
    "                 dim: int = 3,\n",
    "                 conv_mode: str = 'same',\n",
    "                 up_mode: str = 'transposed'\n",
    "                 ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.normalization = normalization\n",
    "        if conv_mode == 'same':\n",
    "            self.padding = 1\n",
    "        elif conv_mode == 'valid':\n",
    "            self.padding = 0\n",
    "        self.dim = dim\n",
    "        self.activation = activation\n",
    "        self.up_mode = up_mode\n",
    "\n",
    "        # upconvolution/upsample layer\n",
    "        self.up = get_up_layer(self.in_channels, self.out_channels, kernel_size=2, stride=2, dim=self.dim,\n",
    "                               up_mode=self.up_mode)\n",
    "\n",
    "        # conv layers\n",
    "        self.conv0 = get_conv_layer(self.in_channels, self.out_channels, kernel_size=1, stride=1, padding=0,\n",
    "                                    bias=True, dim=self.dim)\n",
    "        self.conv1 = get_conv_layer(2 * self.out_channels, self.out_channels, kernel_size=3, stride=1,\n",
    "                                    padding=self.padding,\n",
    "                                    bias=True, dim=self.dim)\n",
    "        self.conv2 = get_conv_layer(self.out_channels, self.out_channels, kernel_size=3, stride=1, padding=self.padding,\n",
    "                                    bias=True, dim=self.dim)\n",
    "\n",
    "        # activation layers\n",
    "        self.act0 = get_activation(self.activation)\n",
    "        self.act1 = get_activation(self.activation)\n",
    "        self.act2 = get_activation(self.activation)\n",
    "\n",
    "        # normalization layers\n",
    "        if self.normalization:\n",
    "            self.norm0 = get_normalization(normalization=self.normalization, num_channels=self.out_channels,\n",
    "                                           dim=self.dim)\n",
    "            self.norm1 = get_normalization(normalization=self.normalization, num_channels=self.out_channels,\n",
    "                                           dim=self.dim)\n",
    "            self.norm2 = get_normalization(normalization=self.normalization, num_channels=self.out_channels,\n",
    "                                           dim=self.dim)\n",
    "\n",
    "        # concatenate layer\n",
    "        self.concat = Concatenate()\n",
    "\n",
    "    def forward(self, encoder_layer, decoder_layer):\n",
    "        \"\"\" Forward pass\n",
    "        Arguments:\n",
    "            encoder_layer: Tensor from the encoder pathway\n",
    "            decoder_layer: Tensor from the decoder pathway (to be up'd)\n",
    "        \"\"\"\n",
    "        up_layer = self.up(decoder_layer)  # up-convolution/up-sampling\n",
    "\n",
    "        if self.up_mode != 'transposed':\n",
    "            # We need to reduce the channel dimension with a conv layer\n",
    "            up_layer = self.conv0(up_layer)  # convolution 0\n",
    "        up_layer = self.act0(up_layer)  # activation 0\n",
    "        if self.normalization:\n",
    "            up_layer = self.norm0(up_layer)  # normalization 0\n",
    "\n",
    "        merged_layer = self.concat(up_layer, encoder_layer)  # concatenation\n",
    "        y = self.conv1(merged_layer)  # convolution 1\n",
    "        y = self.act1(y)  # activation 1\n",
    "        if self.normalization:\n",
    "            y = self.norm1(y)  # normalization 1\n",
    "        y = self.conv2(y)  # convolution 2\n",
    "        y = self.act2(y)  # acivation 2\n",
    "        if self.normalization:\n",
    "            y = self.norm2(y)  # normalization 2\n",
    "        return y\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels: int = 1,\n",
    "                 out_channels: int = 2,\n",
    "                 n_blocks: int = 4,\n",
    "                 start_filters: int = 32,\n",
    "                 activation: str = 'relu',\n",
    "                 normalization: str = 'batch',\n",
    "                 conv_mode: str = 'same',\n",
    "                 dim: int = 2,\n",
    "                 up_mode: str = 'transposed'\n",
    "                 ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.n_blocks = n_blocks\n",
    "        self.start_filters = start_filters\n",
    "        self.activation = activation\n",
    "        self.normalization = normalization\n",
    "        self.conv_mode = conv_mode\n",
    "        self.dim = dim\n",
    "        self.up_mode = up_mode\n",
    "\n",
    "        self.down_blocks = []\n",
    "        self.up_blocks = []\n",
    "\n",
    "        # create encoder path\n",
    "        for i in range(self.n_blocks):\n",
    "            num_filters_in = self.in_channels if i == 0 else num_filters_out\n",
    "            num_filters_out = self.start_filters * (2 ** i)\n",
    "            pooling = True if i < self.n_blocks - 1 else False\n",
    "\n",
    "            down_block = DownBlock(in_channels=num_filters_in,\n",
    "                                   out_channels=num_filters_out,\n",
    "                                   pooling=pooling,\n",
    "                                   activation=self.activation,\n",
    "                                   normalization=self.normalization,\n",
    "                                   conv_mode=self.conv_mode,\n",
    "                                   dim=self.dim)\n",
    "\n",
    "            self.down_blocks.append(down_block)\n",
    "\n",
    "        # create decoder path (requires only n_blocks-1 blocks)\n",
    "        for i in range(n_blocks - 1):\n",
    "            num_filters_in = num_filters_out\n",
    "            num_filters_out = num_filters_in // 2\n",
    "\n",
    "            up_block = UpBlock(in_channels=num_filters_in,\n",
    "                               out_channels=num_filters_out,\n",
    "                               activation=self.activation,\n",
    "                               normalization=self.normalization,\n",
    "                               conv_mode=self.conv_mode,\n",
    "                               dim=self.dim,\n",
    "                               up_mode=self.up_mode)\n",
    "\n",
    "            self.up_blocks.append(up_block)\n",
    "\n",
    "        # final convolution\n",
    "        self.conv_final = get_conv_layer(num_filters_out, self.out_channels, kernel_size=1, stride=1, padding=0,\n",
    "                                         bias=True, dim=self.dim)\n",
    "\n",
    "        # add the list of modules to current module\n",
    "        self.down_blocks = nn.ModuleList(self.down_blocks)\n",
    "        self.up_blocks = nn.ModuleList(self.up_blocks)\n",
    "\n",
    "        # initialize the weights\n",
    "        self.initialize_parameters()\n",
    "\n",
    "    @staticmethod\n",
    "    def weight_init(module, method, **kwargs):\n",
    "        if isinstance(module, (nn.Conv3d, nn.Conv2d, nn.ConvTranspose3d, nn.ConvTranspose2d)):\n",
    "            method(module.weight, **kwargs)  # weights\n",
    "\n",
    "    @staticmethod\n",
    "    def bias_init(module, method, **kwargs):\n",
    "        if isinstance(module, (nn.Conv3d, nn.Conv2d, nn.ConvTranspose3d, nn.ConvTranspose2d)):\n",
    "            method(module.bias, **kwargs)  # bias\n",
    "\n",
    "    def initialize_parameters(self,\n",
    "                              method_weights=nn.init.xavier_uniform_,\n",
    "                              method_bias=nn.init.zeros_,\n",
    "                              kwargs_weights={},\n",
    "                              kwargs_bias={}\n",
    "                              ):\n",
    "        for module in self.modules():\n",
    "            self.weight_init(module, method_weights, **kwargs_weights)  # initialize weights\n",
    "            self.bias_init(module, method_bias, **kwargs_bias)  # initialize bias\n",
    "\n",
    "    def forward(self, x: torch.tensor):\n",
    "        encoder_output = []\n",
    "\n",
    "        # Encoder pathway\n",
    "        for module in self.down_blocks:\n",
    "            x, before_pooling = module(x)\n",
    "            encoder_output.append(before_pooling)\n",
    "\n",
    "        # Decoder pathway\n",
    "        for i, module in enumerate(self.up_blocks):\n",
    "            before_pool = encoder_output[-(i + 2)]\n",
    "            x = module(before_pool, x)\n",
    "\n",
    "        x = self.conv_final(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def __repr__(self):\n",
    "        attributes = {attr_key: self.__dict__[attr_key] for attr_key in self.__dict__.keys() if '_' not in attr_key[0] and 'training' not in attr_key}\n",
    "        d = {self.__class__.__name__: attributes}\n",
    "        return f'{d}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred, label, threshold=0.8):\n",
    "    results = {}\n",
    "    results[\"dice\"] = torchmetrics.functional.dice(pred, label, threshold=0.8).item()\n",
    "    results[\"jaccard\"] = torchmetrics.functional.jaccard_index(pred, label, num_classes=2).item()\n",
    "    pred_bool = pred.cpu().detach().numpy() > threshold\n",
    "    pred_bool = np.reshape(pred_bool, (pred_bool.shape[0], -1))\n",
    "    label_bool = label.cpu().detach().numpy() > threshold\n",
    "    label_bool = np.reshape(label_bool, (label_bool.shape[0], -1))\n",
    "    surface_distances = sf.compute_surface_distances(label_bool, pred_bool, spacing_mm=(2, 2,))\n",
    "    results[\"avg_surface_dist\"] = sf.compute_average_surface_distance(surface_distances)[-1]\n",
    "    results[\"hausdorff\"] = sf.compute_robust_hausdorff(surface_distances, 0.95)\n",
    "    return results\n",
    "\n",
    "LOSS_FUNCTION = {\n",
    "    \"bce\": nn.BCEWithLogitsLoss(),\n",
    "    \"dice\": losses.DiceLoss(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, eval_loader, loss_function=nn.BCEWithLogitsLoss(), device=\"cuda\"):\n",
    "    model.eval()\n",
    "    torch.set_grad_enabled(False)\n",
    "\n",
    "    total_eval_loss = 0\n",
    "    epoch_eval_pred, epoch_eval_target = torch.Tensor().to(device), torch.IntTensor().to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        with tqdm(eval_loader, unit=\"batch\", position=0, leave=True) as tepoch:\n",
    "            for i, (data, target) in enumerate(tepoch):\n",
    "                data, target = data.to(device), target.to(device)\n",
    "\n",
    "                output = model(data)\n",
    "                predictions = torch.sigmoid(output)\n",
    "                epoch_eval_pred = torch.cat((epoch_eval_pred, predictions), dim=0)\n",
    "                epoch_eval_target = torch.cat((epoch_eval_target, target), dim=0)\n",
    "\n",
    "                # Evaluate on eval set\n",
    "                eval_results = compute_metrics(epoch_eval_pred, epoch_eval_target)\n",
    "                \n",
    "                loss = loss_function(output, target.float())\n",
    "                total_eval_loss += loss.item()  # sum up batch loss\n",
    "\n",
    "                tepoch.set_postfix_str(\"EVAL LOSS:{:.4f} EVAL_METRICS:{}\".format(\n",
    "                    total_eval_loss/(i+1), eval_results))\n",
    "    \n",
    "    return {\n",
    "        \"total_loss\": total_eval_loss,\n",
    "        \"iter\": i+1,\n",
    "        \"eval_metrics\": eval_results,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, device=\"cuda\", loss_function=nn.BCEWithLogitsLoss(), reduce_lr_on_plateau=True, early_stop=5, num_epochs=5, max_norm=10.0, log_interval=1):\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    if reduce_lr_on_plateau:\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, \"min\")\n",
    "\n",
    "    result_log = {\n",
    "        \"train_loss\": [],\n",
    "        \"valid_loss\": [],\n",
    "        \"num_epochs\": [],\n",
    "    }\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        torch.set_grad_enabled(True)\n",
    "        total_train_loss = 0\n",
    "        epoch_train_pred, epoch_train_target = torch.Tensor().to(device), torch.Tensor().to(device)\n",
    "        with tqdm(train_loader, unit=\"batch\", position=0, leave=True) as tepoch:\n",
    "            for i, (data, target) in enumerate(tepoch):\n",
    "                tepoch.set_postfix_str(f\"(Epoch {epoch})\")\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                output = model(data)\n",
    "                predictions = torch.sigmoid(output)\n",
    "                epoch_train_pred = torch.cat((epoch_train_pred, predictions), dim=0)\n",
    "                epoch_train_target = torch.cat((epoch_train_target, target), dim=0)\n",
    "\n",
    "                # Evaluate on train set\n",
    "                tepoch.set_postfix_str(f\"(Epoch {epoch}) EVALUATING...\")\n",
    "                train_eval_results = compute_metrics(epoch_train_pred, epoch_train_target.int())\n",
    "                \n",
    "                loss = loss_function(output, target.float())\n",
    "                # Scales the loss, and calls backward() to create scaled gradients\n",
    "                scaler.scale(loss).backward()\n",
    "                # Unscales the gradients of optimizer's assigned params in-place\n",
    "                scaler.unscale_(optimizer)\n",
    "                # Since the gradients of optimizer's assigned params are unscaled, clips as usual:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n",
    "                # Unscales gradients and calls optimizer.step()\n",
    "                scaler.step(optimizer)\n",
    "                # Updates the scale for next iteration\n",
    "                scaler.update()\n",
    "\n",
    "                train_loss = loss.item()\n",
    "                total_train_loss += train_loss\n",
    "                tepoch.set_postfix_str(\"(Epoch {}) TRAIN LOSS:{:.4f} LR:{:.8f} TRAIN_EVAL:{}\".format((epoch+1),\n",
    "                total_train_loss/(i+1), get_lr(optimizer), train_eval_results))\n",
    "\n",
    "            result_log[\"train_loss\"].append(total_train_loss/(i+1))\n",
    "            for k in train_eval_results.keys():    \n",
    "                if result_log.get(f\"train__{k}\") is None:\n",
    "                    result_log[f\"train__{k}\"] = []\n",
    "                result_log[f\"train__{k}\"].append(train_eval_results[k])\n",
    "                \n",
    "            if epoch % log_interval == 0:\n",
    "                avg_train_loss = total_train_loss\n",
    "                # Evaluate on valid set\n",
    "                valid_eval_results = evaluate(model, valid_loader, loss_function=loss_function, device=device)\n",
    "                result_log[\"valid_loss\"].append(valid_eval_results[\"total_loss\"]/valid_eval_results[\"iter\"])\n",
    "                for k in valid_eval_results[\"eval_metrics\"].keys():    \n",
    "                    if result_log.get(f\"valid__{k}\") is None:\n",
    "                        result_log[f\"valid__{k}\"] = []\n",
    "                    result_log[f\"valid__{k}\"].append(valid_eval_results[\"eval_metrics\"][k])\n",
    "\n",
    "            # Early stopping\n",
    "            if min(result_log[\"valid_loss\"]) < result_log[\"valid_loss\"][-1]:\n",
    "                count_stop = 0\n",
    "            else:\n",
    "                count_stop += 1\n",
    "                if count_stop == early_stop:\n",
    "                    break\n",
    "    result_log[\"num_epochs\"] = num_epochs\n",
    "    return model, result_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [01:31<00:00, 91.98s/batch, (Epoch 1) TRAIN LOSS:0.6388 LR:0.00001000 TRAIN_EVAL:{'dice': 0.019654162228107452, 'jaccard': 0.2865646779537201, 'avg_surface_dist': 14.98173388041034, 'hausdorff': 0.0}]\n",
      "  0%|          | 0/1 [00:00<?, ?batch/s]/home/holy/anaconda3/envs/health/lib/python3.10/site-packages/surface_distance/metrics.py:319: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  np.sum(distances_pred_to_gt * surfel_areas_pred) /\n",
      "100%|██████████| 1/1 [01:15<00:00, 75.64s/batch, EVAL LOSS:0.6068 EVAL_METRICS:{'dice': 0.0, 'jaccard': 0.2975121736526489, 'avg_surface_dist': nan, 'hausdorff': inf}]\n",
      "100%|██████████| 1/1 [01:02<00:00, 62.12s/batch, (Epoch 2) TRAIN LOSS:0.7302 LR:0.00001000 TRAIN_EVAL:{'dice': 0.0198227372020483, 'jaccard': 0.2787456810474396, 'avg_surface_dist': 70.06202519297169, 'hausdorff': 0.0}]\n",
      "100%|██████████| 1/1 [01:01<00:00, 61.50s/batch, EVAL LOSS:0.6067 EVAL_METRICS:{'dice': 0.0, 'jaccard': 0.2982635200023651, 'avg_surface_dist': nan, 'hausdorff': inf}]\n",
      "100%|██████████| 1/1 [01:20<00:00, 80.09s/batch, (Epoch 3) TRAIN LOSS:0.6732 LR:0.00001000 TRAIN_EVAL:{'dice': 0.017488038167357445, 'jaccard': 0.2849091589450836, 'avg_surface_dist': 24.05059708417993, 'hausdorff': 0.0}]\n",
      "  0%|          | 0/1 [00:38<?, ?batch/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/holy/projects/ai-healthcare/assignment1/solution.ipynb Cell 18\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Beez115/home/holy/projects/ai-healthcare/assignment1/solution.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Beez115/home/holy/projects/ai-healthcare/assignment1/solution.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m optimizer \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m1e-5\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Beez115/home/holy/projects/ai-healthcare/assignment1/solution.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m model, result_log \u001b[39m=\u001b[39m train(model, train_loader, optimizer, loss_function\u001b[39m=\u001b[39;49mlosses\u001b[39m.\u001b[39;49mDiceLoss())\n",
      "\u001b[1;32m/home/holy/projects/ai-healthcare/assignment1/solution.ipynb Cell 18\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer, device, loss_function, reduce_lr_on_plateau, num_epochs, max_norm, log_interval)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Beez115/home/holy/projects/ai-healthcare/assignment1/solution.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=55'>56</a>\u001b[0m avg_train_loss \u001b[39m=\u001b[39m total_train_loss\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Beez115/home/holy/projects/ai-healthcare/assignment1/solution.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=56'>57</a>\u001b[0m \u001b[39m# Evaluate on valid set\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Beez115/home/holy/projects/ai-healthcare/assignment1/solution.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=57'>58</a>\u001b[0m valid_eval_results \u001b[39m=\u001b[39m evaluate(model, valid_loader, loss_function\u001b[39m=\u001b[39;49mloss_function, device\u001b[39m=\u001b[39;49mdevice)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Beez115/home/holy/projects/ai-healthcare/assignment1/solution.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=58'>59</a>\u001b[0m result_log[\u001b[39m\"\u001b[39m\u001b[39mvalid_loss\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mappend(valid_eval_results[\u001b[39m\"\u001b[39m\u001b[39mtotal_loss\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m/\u001b[39mvalid_eval_results[\u001b[39m\"\u001b[39m\u001b[39miter\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Beez115/home/holy/projects/ai-healthcare/assignment1/solution.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m valid_eval_results[\u001b[39m\"\u001b[39m\u001b[39meval_metrics\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mkeys():    \n",
      "\u001b[1;32m/home/holy/projects/ai-healthcare/assignment1/solution.ipynb Cell 18\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, eval_loader, loss_function, device)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Beez115/home/holy/projects/ai-healthcare/assignment1/solution.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m epoch_eval_target \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((epoch_eval_target, target), dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Beez115/home/holy/projects/ai-healthcare/assignment1/solution.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# Evaluate on eval set\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Beez115/home/holy/projects/ai-healthcare/assignment1/solution.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m eval_results \u001b[39m=\u001b[39m compute_metrics(epoch_eval_pred, epoch_eval_target)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Beez115/home/holy/projects/ai-healthcare/assignment1/solution.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_function(output, target\u001b[39m.\u001b[39mfloat())\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Beez115/home/holy/projects/ai-healthcare/assignment1/solution.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m total_eval_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()  \u001b[39m# sum up batch loss\u001b[39;00m\n",
      "\u001b[1;32m/home/holy/projects/ai-healthcare/assignment1/solution.ipynb Cell 18\u001b[0m in \u001b[0;36mcompute_metrics\u001b[0;34m(pred, label, threshold)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Beez115/home/holy/projects/ai-healthcare/assignment1/solution.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m results \u001b[39m=\u001b[39m {}\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Beez115/home/holy/projects/ai-healthcare/assignment1/solution.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m results[\u001b[39m\"\u001b[39m\u001b[39mdice\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m torchmetrics\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mdice(pred, label, threshold\u001b[39m=\u001b[39m\u001b[39m0.8\u001b[39m)\u001b[39m.\u001b[39mitem()\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Beez115/home/holy/projects/ai-healthcare/assignment1/solution.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m results[\u001b[39m\"\u001b[39m\u001b[39mjaccard\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m torchmetrics\u001b[39m.\u001b[39;49mfunctional\u001b[39m.\u001b[39;49mjaccard_index(pred, label, num_classes\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\u001b[39m.\u001b[39mitem()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Beez115/home/holy/projects/ai-healthcare/assignment1/solution.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m pred_bool \u001b[39m=\u001b[39m pred\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mnumpy() \u001b[39m>\u001b[39m threshold\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Beez115/home/holy/projects/ai-healthcare/assignment1/solution.ipynb#X23sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m pred_bool \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mreshape(pred_bool, (pred_bool\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/envs/health/lib/python3.10/site-packages/torchmetrics/functional/classification/jaccard.py:475\u001b[0m, in \u001b[0;36mjaccard_index\u001b[0;34m(preds, target, num_classes, average, ignore_index, absent_score, threshold, task, num_labels, validate_args)\u001b[0m\n\u001b[1;32m    466\u001b[0m     rank_zero_warn(\n\u001b[1;32m    467\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFrom v0.10 an `\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary_*\u001b[39m\u001b[39m'\u001b[39m\u001b[39m`, `\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmulticlass_*\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, `\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmultilabel_*\u001b[39m\u001b[39m'\u001b[39m\u001b[39m` version now exist of each classification\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    468\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m metric. Moving forward we recommend using these versions. This base metric will still work as it did\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    472\u001b[0m         \u001b[39mDeprecationWarning\u001b[39;00m,\n\u001b[1;32m    473\u001b[0m     )\n\u001b[1;32m    474\u001b[0m confmat \u001b[39m=\u001b[39m _confusion_matrix_update(preds, target, num_classes, threshold)\n\u001b[0;32m--> 475\u001b[0m \u001b[39mreturn\u001b[39;00m _jaccard_from_confmat(confmat, num_classes, average, ignore_index, absent_score)\n",
      "File \u001b[0;32m~/anaconda3/envs/health/lib/python3.10/site-packages/torchmetrics/functional/classification/jaccard.py:357\u001b[0m, in \u001b[0;36m_jaccard_from_confmat\u001b[0;34m(confmat, num_classes, average, ignore_index, absent_score)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[39mreturn\u001b[39;00m scores\n\u001b[1;32m    356\u001b[0m \u001b[39mif\u001b[39;00m average \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmacro\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 357\u001b[0m     scores \u001b[39m=\u001b[39m _jaccard_from_confmat(\n\u001b[1;32m    358\u001b[0m         confmat, num_classes, average\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mnone\u001b[39;49m\u001b[39m\"\u001b[39;49m, ignore_index\u001b[39m=\u001b[39;49mignore_index, absent_score\u001b[39m=\u001b[39;49mabsent_score\n\u001b[1;32m    359\u001b[0m     )\n\u001b[1;32m    360\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mmean(scores)\n\u001b[1;32m    362\u001b[0m \u001b[39mif\u001b[39;00m average \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmicro\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/health/lib/python3.10/site-packages/torchmetrics/functional/classification/jaccard.py:345\u001b[0m, in \u001b[0;36m_jaccard_from_confmat\u001b[0;34m(confmat, num_classes, average, ignore_index, absent_score)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[39m# If this class is absent in both target AND pred (union == 0), then use the absent_score for this class.\u001b[39;00m\n\u001b[1;32m    344\u001b[0m scores \u001b[39m=\u001b[39m intersection\u001b[39m.\u001b[39mfloat() \u001b[39m/\u001b[39m union\u001b[39m.\u001b[39mfloat()\n\u001b[0;32m--> 345\u001b[0m scores \u001b[39m=\u001b[39m scores\u001b[39m.\u001b[39mwhere(union \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m, torch\u001b[39m.\u001b[39;49mtensor(absent_score, dtype\u001b[39m=\u001b[39;49mscores\u001b[39m.\u001b[39;49mdtype, device\u001b[39m=\u001b[39;49mscores\u001b[39m.\u001b[39;49mdevice))\n\u001b[1;32m    347\u001b[0m \u001b[39mif\u001b[39;00m ignore_index \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39m0\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m ignore_index \u001b[39m<\u001b[39m num_classes:\n\u001b[1;32m    348\u001b[0m     scores \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(\n\u001b[1;32m    349\u001b[0m         [\n\u001b[1;32m    350\u001b[0m             scores[:ignore_index],\n\u001b[1;32m    351\u001b[0m             scores[ignore_index \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m :],\n\u001b[1;32m    352\u001b[0m         ]\n\u001b[1;32m    353\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = UNet(in_channels=112,\n",
    "             out_channels=112,\n",
    "             n_blocks=4,\n",
    "             start_filters=32,\n",
    "             activation='relu',\n",
    "             normalization='batch',\n",
    "             conv_mode='same',\n",
    "             dim=2)\n",
    "model = model.cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "model, result_log = train(model, train_loader, optimizer, loss_function=losses.DiceLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('health')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d2f67f6f02098114f1eb667dbde229539e133e34a85b887b9dc3eea951e127e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
