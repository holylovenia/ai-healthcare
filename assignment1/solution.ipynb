{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ELEC6910X Advanced Topics in AI and Healthcare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Holy Lovenia - 20814158***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from pytorch3dunet.unet3d import losses\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import init\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from tqdm import tqdm\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import surface_distance.metrics as sf\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchio as tio\n",
    "import torchmetrics\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "\n",
    "def set_all_seeds(seed):\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  torch.manual_seed(seed)\n",
    "  torch.cuda.manual_seed(seed)\n",
    "  torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_all_seeds(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem, you are required to implement a 3D segmentation network (e.g., 3d unet), including\n",
    "the model, dataloader, training/testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Problem1Dataset(Dataset):\n",
    "    def __init__(self, dir_path, column_names=[\"image\", \"label\"], resize_type=\"center\", resize_target_shape=(112, 112, 88), transform=None, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.dir_path = dir_path\n",
    "        self.column_names = column_names\n",
    "        self.transform = transform\n",
    "        self.resize_type = resize_type\n",
    "        self.resize_target_shape = resize_target_shape\n",
    "        self._init_transform_methods()\n",
    "        self._load_all_data_from_dir(dir_path)\n",
    "    \n",
    "    def _load_h5_data(self, file_path):\n",
    "        hf = h5py.File(file_path, \"r\")\n",
    "        return hf\n",
    "\n",
    "    def _load_all_data_from_dir(self, dir_path):\n",
    "        df_dict = {}\n",
    "        for col in self.column_names:\n",
    "            df_dict[col] = []\n",
    "\n",
    "        for file_name in os.listdir(dir_path):\n",
    "            file_path = os.path.join(dir_path, file_name)\n",
    "            if os.path.isfile(file_path) and file_path.endswith(\".h5\"):\n",
    "                data = self._load_h5_data(file_path)\n",
    "                for col in self.column_names:\n",
    "                    df_dict[col] += [np.array(data[col][:])]\n",
    "        self.dataset = pd.DataFrame.from_dict(df_dict)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        current_data = self.dataset.iloc[index]\n",
    "        transformed = self.set_transform(current_data[\"image\"], current_data[\"label\"])\n",
    "        return transformed\n",
    "\n",
    "    def _init_transform_methods(self):\n",
    "        self._random_affine = tio.RandomAffine(scales=(0.9, 1.2), degrees=15)\n",
    "        self._random_motion = tio.RandomMotion()\n",
    "        self._random_elastic_deformation = tio.RandomElasticDeformation()\n",
    "        self._random_blur = tio.RandomBlur()\n",
    "        self._random_transform = tio.OneOf({\n",
    "            self._random_affine: 0.25,\n",
    "            self._random_motion: 0.25,\n",
    "            self._random_elastic_deformation: 0.25,\n",
    "            self._random_blur: 0.25,\n",
    "        })\n",
    "        self._random_double = tio.Compose([self._random_transform, self._random_transform])\n",
    "        self._crop_or_pad = tio.CropOrPad(self.resize_target_shape)\n",
    "\n",
    "    def set_transform(self, data, label):\n",
    "        transformed_data, transformed_label = self.resize(data, label)\n",
    "\n",
    "        if self.transform is None:\n",
    "            return transformed_data, transformed_label\n",
    "\n",
    "        if self.transform == \"random\":\n",
    "            transform_method = self._random_transform\n",
    "        elif self.transform == \"motion\":\n",
    "            transform_method = self._random_motion\n",
    "        elif self.transform == \"affine\":\n",
    "            transform_method = self._random_affine\n",
    "        elif self.transform == \"elastic_deformation\":\n",
    "            transform_method = self._random_elastic_deformation\n",
    "        elif self.transform == \"random_double\":\n",
    "            transform_method = self._random_double\n",
    "\n",
    "        transformed_data = np.expand_dims(transformed_data, axis=0)\n",
    "        transformed_data = transform_method(transformed_data)\n",
    "        transformed_data = np.squeeze(transformed_data, axis=0)\n",
    "\n",
    "        transformed_label = np.expand_dims(transformed_label, axis=0)\n",
    "        transformed_label = transform_method(transformed_label)\n",
    "        transformed_label = np.squeeze(transformed_label, axis=0)\n",
    "\n",
    "        return transformed_data, transformed_label\n",
    "\n",
    "    def resize(self, data, label):\n",
    "        if self.resize_type == \"center\":\n",
    "            transformed_data = np.expand_dims(data, axis=0)\n",
    "            transformed_data = self._crop_or_pad(transformed_data)\n",
    "            transformed_data = np.squeeze(transformed_data, axis=0)\n",
    "            transformed_label = np.expand_dims(label, axis=0)\n",
    "            transformed_label = self._crop_or_pad(transformed_label)\n",
    "            transformed_label = np.squeeze(transformed_label, axis=0)\n",
    "            return transformed_data, transformed_label\n",
    "        elif self.resize_type == \"random\":\n",
    "            return get_random_crop(data, label, crop_width=self.resize_target_shape[0], crop_height=self.resize_target_shape[1])\n",
    "\n",
    "def get_random_crop(data, label, crop_width, crop_height):\n",
    "    max_w = data.shape[1] - crop_width\n",
    "    max_h = data.shape[0] - crop_height\n",
    "    w = np.random.randint(0, max_w)\n",
    "    h = np.random.randint(0, max_h)\n",
    "    cropped_data = data[h: h + crop_height, w: w + crop_width, :]\n",
    "    cropped_label = label[h: h + crop_height, w: w + crop_width, :]\n",
    "    return cropped_data, cropped_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Problem1Dataset(\"./data/problem1_datas/train\", resize_type=\"random\", resize_target_shape=(112, 112, 88), transform=\"random\")\n",
    "valid_dataset = Problem1Dataset(\"./data/problem1_datas/train\", resize_type=\"center\", resize_target_shape=(112, 112, 88), transform=None)\n",
    "test_dataset = Problem1Dataset(\"./data/problem1_datas/test\", resize_type=\"center\", resize_target_shape=(112, 112, 88), transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=4, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "\n",
    "@torch.jit.script\n",
    "def autocrop(encoder_layer: torch.Tensor, decoder_layer: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Center-crops the encoder_layer to the size of the decoder_layer,\n",
    "    so that merging (concatenation) between levels/blocks is possible.\n",
    "    This is only necessary for input sizes != 2**n for 'same' padding and always required for 'valid' padding.\n",
    "    \"\"\"\n",
    "    if encoder_layer.shape[2:] != decoder_layer.shape[2:]:\n",
    "        ds = encoder_layer.shape[2:]\n",
    "        es = decoder_layer.shape[2:]\n",
    "        assert ds[0] >= es[0]\n",
    "        assert ds[1] >= es[1]\n",
    "        if encoder_layer.dim() == 4:  # 2D\n",
    "            encoder_layer = encoder_layer[\n",
    "                            :,\n",
    "                            :,\n",
    "                            ((ds[0] - es[0]) // 2):((ds[0] + es[0]) // 2),\n",
    "                            ((ds[1] - es[1]) // 2):((ds[1] + es[1]) // 2)\n",
    "                            ]\n",
    "        elif encoder_layer.dim() == 5:  # 3D\n",
    "            assert ds[2] >= es[2]\n",
    "            encoder_layer = encoder_layer[\n",
    "                            :,\n",
    "                            :,\n",
    "                            ((ds[0] - es[0]) // 2):((ds[0] + es[0]) // 2),\n",
    "                            ((ds[1] - es[1]) // 2):((ds[1] + es[1]) // 2),\n",
    "                            ((ds[2] - es[2]) // 2):((ds[2] + es[2]) // 2),\n",
    "                            ]\n",
    "    return encoder_layer, decoder_layer\n",
    "\n",
    "\n",
    "def conv_layer(dim: int):\n",
    "    if dim == 3:\n",
    "        return nn.Conv3d\n",
    "    elif dim == 2:\n",
    "        return nn.Conv2d\n",
    "\n",
    "\n",
    "def get_conv_layer(in_channels: int,\n",
    "                   out_channels: int,\n",
    "                   kernel_size: int = 3,\n",
    "                   stride: int = 1,\n",
    "                   padding: int = 1,\n",
    "                   bias: bool = True,\n",
    "                   dim: int = 2):\n",
    "    return conv_layer(dim)(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding,\n",
    "                           bias=bias)\n",
    "\n",
    "\n",
    "def conv_transpose_layer(dim: int):\n",
    "    if dim == 3:\n",
    "        return nn.ConvTranspose3d\n",
    "    elif dim == 2:\n",
    "        return nn.ConvTranspose2d\n",
    "\n",
    "\n",
    "def get_up_layer(in_channels: int,\n",
    "                 out_channels: int,\n",
    "                 kernel_size: int = 2,\n",
    "                 stride: int = 2,\n",
    "                 dim: int = 3,\n",
    "                 up_mode: str = 'transposed',\n",
    "                 ):\n",
    "    if up_mode == 'transposed':\n",
    "        return conv_transpose_layer(dim)(in_channels, out_channels, kernel_size=kernel_size, stride=stride)\n",
    "    else:\n",
    "        return nn.Upsample(scale_factor=2.0, mode=up_mode)\n",
    "\n",
    "\n",
    "def maxpool_layer(dim: int):\n",
    "    if dim == 3:\n",
    "        return nn.MaxPool3d\n",
    "    elif dim == 2:\n",
    "        return nn.MaxPool2d\n",
    "\n",
    "\n",
    "def get_maxpool_layer(kernel_size: int = 2,\n",
    "                      stride: int = 2,\n",
    "                      padding: int = 0,\n",
    "                      dim: int = 2):\n",
    "    return maxpool_layer(dim=dim)(kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "\n",
    "\n",
    "def get_activation(activation: str):\n",
    "    if activation == 'relu':\n",
    "        return nn.ReLU()\n",
    "    elif activation == 'leaky':\n",
    "        return nn.LeakyReLU(negative_slope=0.1)\n",
    "    elif activation == 'elu':\n",
    "        return nn.ELU()\n",
    "\n",
    "\n",
    "def get_normalization(normalization: str,\n",
    "                      num_channels: int,\n",
    "                      dim: int):\n",
    "    if normalization == 'batch':\n",
    "        if dim == 3:\n",
    "            return nn.BatchNorm3d(num_channels)\n",
    "        elif dim == 2:\n",
    "            return nn.BatchNorm2d(num_channels)\n",
    "    elif normalization == 'instance':\n",
    "        if dim == 3:\n",
    "            return nn.InstanceNorm3d(num_channels)\n",
    "        elif dim == 2:\n",
    "            return nn.InstanceNorm2d(num_channels)\n",
    "    elif 'group' in normalization:\n",
    "        num_groups = int(normalization.partition('group')[-1])  # get the group size from string\n",
    "        return nn.GroupNorm(num_groups=num_groups, num_channels=num_channels)\n",
    "\n",
    "\n",
    "class Concatenate(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Concatenate, self).__init__()\n",
    "\n",
    "    def forward(self, layer_1, layer_2):\n",
    "        x = torch.cat((layer_1, layer_2), 1)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class DownBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    A helper Module that performs 2 Convolutions and 1 MaxPool.\n",
    "    An activation follows each convolution.\n",
    "    A normalization layer follows each convolution.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 out_channels: int,\n",
    "                 pooling: bool = True,\n",
    "                 activation: str = 'relu',\n",
    "                 normalization: str = None,\n",
    "                 dim: str = 2,\n",
    "                 conv_mode: str = 'same'):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.pooling = pooling\n",
    "        self.normalization = normalization\n",
    "        if conv_mode == 'same':\n",
    "            self.padding = 1\n",
    "        elif conv_mode == 'valid':\n",
    "            self.padding = 0\n",
    "        self.dim = dim\n",
    "        self.activation = activation\n",
    "\n",
    "        # conv layers\n",
    "        self.conv1 = get_conv_layer(self.in_channels, self.out_channels, kernel_size=3, stride=1, padding=self.padding,\n",
    "                                    bias=True, dim=self.dim)\n",
    "        self.conv2 = get_conv_layer(self.out_channels, self.out_channels, kernel_size=3, stride=1, padding=self.padding,\n",
    "                                    bias=True, dim=self.dim)\n",
    "\n",
    "        # pooling layer\n",
    "        if self.pooling:\n",
    "            self.pool = get_maxpool_layer(kernel_size=2, stride=2, padding=0, dim=self.dim)\n",
    "\n",
    "        # activation layers\n",
    "        self.act1 = get_activation(self.activation)\n",
    "        self.act2 = get_activation(self.activation)\n",
    "\n",
    "        # normalization layers\n",
    "        if self.normalization:\n",
    "            self.norm1 = get_normalization(normalization=self.normalization, num_channels=self.out_channels,\n",
    "                                           dim=self.dim)\n",
    "            self.norm2 = get_normalization(normalization=self.normalization, num_channels=self.out_channels,\n",
    "                                           dim=self.dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.conv1(x)  # convolution 1\n",
    "        y = self.act1(y)  # activation 1\n",
    "        if self.normalization:\n",
    "            y = self.norm1(y)  # normalization 1\n",
    "        y = self.conv2(y)  # convolution 2\n",
    "        y = self.act2(y)  # activation 2\n",
    "        if self.normalization:\n",
    "            y = self.norm2(y)  # normalization 2\n",
    "\n",
    "        before_pooling = y  # save the outputs before the pooling operation\n",
    "        if self.pooling:\n",
    "            y = self.pool(y)  # pooling\n",
    "        return y, before_pooling\n",
    "\n",
    "\n",
    "class UpBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    A helper Module that performs 2 Convolutions and 1 UpConvolution/Upsample.\n",
    "    An activation follows each convolution.\n",
    "    A normalization layer follows each convolution.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 out_channels: int,\n",
    "                 activation: str = 'relu',\n",
    "                 normalization: str = None,\n",
    "                 dim: int = 3,\n",
    "                 conv_mode: str = 'same',\n",
    "                 up_mode: str = 'transposed'\n",
    "                 ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.normalization = normalization\n",
    "        if conv_mode == 'same':\n",
    "            self.padding = 1\n",
    "        elif conv_mode == 'valid':\n",
    "            self.padding = 0\n",
    "        self.dim = dim\n",
    "        self.activation = activation\n",
    "        self.up_mode = up_mode\n",
    "\n",
    "        # upconvolution/upsample layer\n",
    "        self.up = get_up_layer(self.in_channels, self.out_channels, kernel_size=2, stride=2, dim=self.dim,\n",
    "                               up_mode=self.up_mode)\n",
    "\n",
    "        # conv layers\n",
    "        self.conv0 = get_conv_layer(self.in_channels, self.out_channels, kernel_size=1, stride=1, padding=0,\n",
    "                                    bias=True, dim=self.dim)\n",
    "        self.conv1 = get_conv_layer(2 * self.out_channels, self.out_channels, kernel_size=3, stride=1,\n",
    "                                    padding=self.padding,\n",
    "                                    bias=True, dim=self.dim)\n",
    "        self.conv2 = get_conv_layer(self.out_channels, self.out_channels, kernel_size=3, stride=1, padding=self.padding,\n",
    "                                    bias=True, dim=self.dim)\n",
    "\n",
    "        # activation layers\n",
    "        self.act0 = get_activation(self.activation)\n",
    "        self.act1 = get_activation(self.activation)\n",
    "        self.act2 = get_activation(self.activation)\n",
    "\n",
    "        # normalization layers\n",
    "        if self.normalization:\n",
    "            self.norm0 = get_normalization(normalization=self.normalization, num_channels=self.out_channels,\n",
    "                                           dim=self.dim)\n",
    "            self.norm1 = get_normalization(normalization=self.normalization, num_channels=self.out_channels,\n",
    "                                           dim=self.dim)\n",
    "            self.norm2 = get_normalization(normalization=self.normalization, num_channels=self.out_channels,\n",
    "                                           dim=self.dim)\n",
    "\n",
    "        # concatenate layer\n",
    "        self.concat = Concatenate()\n",
    "\n",
    "    def forward(self, encoder_layer, decoder_layer):\n",
    "        \"\"\" Forward pass\n",
    "        Arguments:\n",
    "            encoder_layer: Tensor from the encoder pathway\n",
    "            decoder_layer: Tensor from the decoder pathway (to be up'd)\n",
    "        \"\"\"\n",
    "        up_layer = self.up(decoder_layer)  # up-convolution/up-sampling\n",
    "\n",
    "        if self.up_mode != 'transposed':\n",
    "            # We need to reduce the channel dimension with a conv layer\n",
    "            up_layer = self.conv0(up_layer)  # convolution 0\n",
    "        up_layer = self.act0(up_layer)  # activation 0\n",
    "        if self.normalization:\n",
    "            up_layer = self.norm0(up_layer)  # normalization 0\n",
    "\n",
    "        merged_layer = self.concat(up_layer, encoder_layer)  # concatenation\n",
    "        y = self.conv1(merged_layer)  # convolution 1\n",
    "        y = self.act1(y)  # activation 1\n",
    "        if self.normalization:\n",
    "            y = self.norm1(y)  # normalization 1\n",
    "        y = self.conv2(y)  # convolution 2\n",
    "        y = self.act2(y)  # acivation 2\n",
    "        if self.normalization:\n",
    "            y = self.norm2(y)  # normalization 2\n",
    "        return y\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels: int = 1,\n",
    "                 out_channels: int = 2,\n",
    "                 n_blocks: int = 4,\n",
    "                 start_filters: int = 32,\n",
    "                 activation: str = 'relu',\n",
    "                 normalization: str = 'batch',\n",
    "                 conv_mode: str = 'same',\n",
    "                 dim: int = 2,\n",
    "                 up_mode: str = 'transposed'\n",
    "                 ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.n_blocks = n_blocks\n",
    "        self.start_filters = start_filters\n",
    "        self.activation = activation\n",
    "        self.normalization = normalization\n",
    "        self.conv_mode = conv_mode\n",
    "        self.dim = dim\n",
    "        self.up_mode = up_mode\n",
    "\n",
    "        self.down_blocks = []\n",
    "        self.up_blocks = []\n",
    "\n",
    "        # create encoder path\n",
    "        for i in range(self.n_blocks):\n",
    "            num_filters_in = self.in_channels if i == 0 else num_filters_out\n",
    "            num_filters_out = self.start_filters * (2 ** i)\n",
    "            pooling = True if i < self.n_blocks - 1 else False\n",
    "\n",
    "            down_block = DownBlock(in_channels=num_filters_in,\n",
    "                                   out_channels=num_filters_out,\n",
    "                                   pooling=pooling,\n",
    "                                   activation=self.activation,\n",
    "                                   normalization=self.normalization,\n",
    "                                   conv_mode=self.conv_mode,\n",
    "                                   dim=self.dim)\n",
    "\n",
    "            self.down_blocks.append(down_block)\n",
    "\n",
    "        # create decoder path (requires only n_blocks-1 blocks)\n",
    "        for i in range(n_blocks - 1):\n",
    "            num_filters_in = num_filters_out\n",
    "            num_filters_out = num_filters_in // 2\n",
    "\n",
    "            up_block = UpBlock(in_channels=num_filters_in,\n",
    "                               out_channels=num_filters_out,\n",
    "                               activation=self.activation,\n",
    "                               normalization=self.normalization,\n",
    "                               conv_mode=self.conv_mode,\n",
    "                               dim=self.dim,\n",
    "                               up_mode=self.up_mode)\n",
    "\n",
    "            self.up_blocks.append(up_block)\n",
    "\n",
    "        # final convolution\n",
    "        self.conv_final = get_conv_layer(num_filters_out, self.out_channels, kernel_size=1, stride=1, padding=0,\n",
    "                                         bias=True, dim=self.dim)\n",
    "\n",
    "        # add the list of modules to current module\n",
    "        self.down_blocks = nn.ModuleList(self.down_blocks)\n",
    "        self.up_blocks = nn.ModuleList(self.up_blocks)\n",
    "\n",
    "        # initialize the weights\n",
    "        self.initialize_parameters()\n",
    "\n",
    "    @staticmethod\n",
    "    def weight_init(module, method, **kwargs):\n",
    "        if isinstance(module, (nn.Conv3d, nn.Conv2d, nn.ConvTranspose3d, nn.ConvTranspose2d)):\n",
    "            method(module.weight, **kwargs)  # weights\n",
    "\n",
    "    @staticmethod\n",
    "    def bias_init(module, method, **kwargs):\n",
    "        if isinstance(module, (nn.Conv3d, nn.Conv2d, nn.ConvTranspose3d, nn.ConvTranspose2d)):\n",
    "            method(module.bias, **kwargs)  # bias\n",
    "\n",
    "    def initialize_parameters(self,\n",
    "                              method_weights=nn.init.xavier_uniform_,\n",
    "                              method_bias=nn.init.zeros_,\n",
    "                              kwargs_weights={},\n",
    "                              kwargs_bias={}\n",
    "                              ):\n",
    "        for module in self.modules():\n",
    "            self.weight_init(module, method_weights, **kwargs_weights)  # initialize weights\n",
    "            self.bias_init(module, method_bias, **kwargs_bias)  # initialize bias\n",
    "\n",
    "    def forward(self, x: torch.tensor):\n",
    "        encoder_output = []\n",
    "\n",
    "        # Encoder pathway\n",
    "        for module in self.down_blocks:\n",
    "            x, before_pooling = module(x)\n",
    "            encoder_output.append(before_pooling)\n",
    "\n",
    "        # Decoder pathway\n",
    "        for i, module in enumerate(self.up_blocks):\n",
    "            before_pool = encoder_output[-(i + 2)]\n",
    "            x = module(before_pool, x)\n",
    "\n",
    "        x = self.conv_final(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def __repr__(self):\n",
    "        attributes = {attr_key: self.__dict__[attr_key] for attr_key in self.__dict__.keys() if '_' not in attr_key[0] and 'training' not in attr_key}\n",
    "        d = {self.__class__.__name__: attributes}\n",
    "        return f'{d}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred, label, threshold=0.8):\n",
    "    results = {}\n",
    "    results[\"dice\"] = torchmetrics.functional.dice(pred, label, threshold=0.8).item()\n",
    "    results[\"jaccard\"] = torchmetrics.functional.jaccard_index(pred, label, num_classes=2).item()\n",
    "    pred_bool = pred.cpu().detach().numpy() > threshold\n",
    "    pred_bool = np.reshape(pred_bool, (pred_bool.shape[0], -1))\n",
    "    label_bool = label.cpu().detach().numpy() > threshold\n",
    "    label_bool = np.reshape(label_bool, (label_bool.shape[0], -1))\n",
    "    surface_distances = sf.compute_surface_distances(label_bool, pred_bool, spacing_mm=(2, 2,))\n",
    "    results[\"avg_surface_dist\"] = sf.compute_average_surface_distance(surface_distances)[-1]\n",
    "    results[\"hausdorff\"] = sf.compute_robust_hausdorff(surface_distances, 0.95)\n",
    "    return results\n",
    "\n",
    "LOSS_FUNCTION = {\n",
    "    \"bce\": nn.BCEWithLogitsLoss(),\n",
    "    \"dice\": losses.DiceLoss(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, eval_loader, loss_function=nn.BCEWithLogitsLoss(), device=\"cuda\"):\n",
    "    model.eval()\n",
    "    torch.set_grad_enabled(False)\n",
    "\n",
    "    total_eval_loss = 0\n",
    "    epoch_eval_pred, epoch_eval_target = torch.Tensor().to(device), torch.IntTensor().to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        with tqdm(eval_loader, unit=\"batch\", position=0, leave=True) as tepoch:\n",
    "            for i, (data, target) in enumerate(tepoch):\n",
    "                data, target = data.to(device), target.to(device)\n",
    "\n",
    "                output = model(data)\n",
    "                predictions = torch.sigmoid(output)\n",
    "                epoch_eval_pred = torch.cat((epoch_eval_pred, predictions), dim=0)\n",
    "                epoch_eval_target = torch.cat((epoch_eval_target, target), dim=0)\n",
    "\n",
    "                # Evaluate on eval set\n",
    "                eval_results = compute_metrics(epoch_eval_pred, epoch_eval_target)\n",
    "                \n",
    "                loss = loss_function(output, target.float())\n",
    "                total_eval_loss += loss.item()  # sum up batch loss\n",
    "\n",
    "                tepoch.set_description(\"EVAL LOSS:{:.4f} EVAL_METRICS:{}\".format(\n",
    "                    total_eval_loss/(i+1), eval_results))\n",
    "    \n",
    "    return {\n",
    "        \"avg_loss\": total_eval_loss/(i+1),\n",
    "        \"eval_metrics\": eval_results,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, device=\"cuda\", loss_function=nn.BCEWithLogitsLoss(), reduce_lr_on_plateau=True, num_epochs=100, max_norm=10.0, log_interval=1):\n",
    "    \n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    if reduce_lr_on_plateau:\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, \"min\")\n",
    "\n",
    "    total_train_loss = 0\n",
    "    epoch_train_pred, epoch_train_target = torch.Tensor().to(device), torch.Tensor().to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        torch.set_grad_enabled(True)\n",
    "        with tqdm(train_loader, unit=\"batch\", position=0, leave=True) as tepoch:\n",
    "            for i, (data, target) in enumerate(tepoch):\n",
    "                tepoch.set_description(f\"Epoch {epoch}\")\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                output = model(data)\n",
    "                predictions = torch.sigmoid(output)\n",
    "                epoch_train_pred = torch.cat((epoch_train_pred, predictions), dim=0)\n",
    "                epoch_train_target = torch.cat((epoch_train_target, target), dim=0)\n",
    "\n",
    "                # Evaluate on train set\n",
    "                train_eval_results = compute_metrics(epoch_train_pred, epoch_train_target.int())\n",
    "                \n",
    "                loss = loss_function(output, target.float())\n",
    "                # Scales the loss, and calls backward() to create scaled gradients\n",
    "                scaler.scale(loss).backward()\n",
    "                # Unscales the gradients of optimizer's assigned params in-place\n",
    "                scaler.unscale_(optimizer)\n",
    "                # Since the gradients of optimizer's assigned params are unscaled, clips as usual:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n",
    "                # Unscales gradients and calls optimizer.step()\n",
    "                scaler.step(optimizer)\n",
    "                # Updates the scale for next iteration\n",
    "                scaler.update()\n",
    "\n",
    "                train_loss = loss.item()\n",
    "                total_train_loss += train_loss\n",
    "                tepoch.set_description(\"(Epoch {}) TRAIN LOSS:{:.4f} LR:{:.8f} TRAIN_EVAL:{}\".format((epoch+1),\n",
    "                total_train_loss/(i+1), get_lr(optimizer), train_eval_results))\n",
    "                \n",
    "            if epoch % log_interval == 0:\n",
    "                # Evaluate on valid set\n",
    "                valid_eval_results = evaluate(model, valid_loader, loss_function=loss_function, device=device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:  75%|███████▌  | 3/4 [01:43<00:38, 38.18s/batch]                                                                                                                                                                    "
     ]
    }
   ],
   "source": [
    "model = UNet(in_channels=112,\n",
    "             out_channels=112,\n",
    "             n_blocks=4,\n",
    "             start_filters=32,\n",
    "             activation='relu',\n",
    "             normalization='batch',\n",
    "             conv_mode='same',\n",
    "             dim=2)\n",
    "model = model.cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "model = train(model, train_loader, optimizer, loss_function=losses.DiceLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('health')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d2f67f6f02098114f1eb667dbde229539e133e34a85b887b9dc3eea951e127e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
